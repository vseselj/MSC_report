\documentclass[a4paper, openany, oneside, 11pt]{book} 
\usepackage[top=3cm, bottom=3cm, left=2.75cm, right=2.75cm]{geometry}

% structure packages
\usepackage{subfiles}
\usepackage[nottoc]{tocbibind}
\usepackage{makeidx} 
	\makeindex
\usepackage{enumitem}
\usepackage{fancyhdr} % fancy headder
	\setlength{\headheight}{15pt}
	\pagestyle{fancy}
	\renewcommand{\chaptermark}[1]{\markboth{#1}{}}
	\renewcommand{\sectionmark}[1]{\markright{#1}{}}
	\fancyhf{}
	\fancyhead[LE,RO]{\thepage}
	\fancyhead[LO]{{\nouppercase{\leftmark}}}
	\fancyhead[RE]{{\nouppercase{\leftmark}}} 
	\fancypagestyle{plain}{
	\fancyhf{} 
	\renewcommand{\headrulewidth}{0pt} 
	\renewcommand{\footrulewidth}{0pt}}

\usepackage{blindtext}
\usepackage{titlesec}
\usepackage{color}
    \definecolor{gray75}{gray}{0.75}
    \titleformat{\chapter}[hang]{\Huge\bfseries}{\thechapter\hspace{15pt}\textcolor{gray75}{$|$}\hspace{15pt}}{0pt}{\Huge\bfseries}

\setcounter{tocdepth}{4}
\setcounter{secnumdepth}{4}

% language settings
\usepackage[english,serbian]{babel}
\usepackage[utf8x]{inputenc} 
\usepackage[OT2,OT1]{fontenc} 
\usepackage[german=quotes]{csquotes}
\DeclareQuoteAlias{dutch}{serbian}

% character conversion settings
\renewcommand{\rmdefault}{wncyr} 
\renewcommand{\sfdefault}{wncyss}
\renewcommand{\encodingdefault}{OT2}

% figures, graphics \& plots
\usepackage[pdftex]{graphicx}
	\graphicspath{{res/}{../res/}}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage{caption}
\usepackage[list=true,listformat=simple]{subcaption} 
\usepackage{pgfplots}
\usepackage{pgfplotstable}

\usepackage{tikz}
\usetikzlibrary{calc,patterns,decorations.pathmorphing,decorations.markings}
\usetikzlibrary{arrows, shapes, calc, positioning, chains, backgrounds}
\usetikzlibrary{circuits.logic.US}
\tikzstyle{gnd}=[fill, pattern = north east lines, draw = none, minimum width = 1.00cm, minimum height = 0.05cm]
\usetikzlibrary{shadings, calc, decorations.markings}
\tikzset{->-/.style={decoration={markings,mark=at position #1 with {\arrow{>}}},postaction={decorate}},>-/.default=0.5,}

\usepackage{multirow}
\usepackage{pdflscape}
\usepackage{listings}
\usepackage{adjustbox}
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{purple},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\scriptsize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
\lstset{style=mystyle}


\usepackage[title]{appendix}

% styles
\usepackage{tcolorbox}
\usepackage{color, colortbl}
\definecolor{Gray}{gray}{0.9}
\usepackage{lipsum}
\usepackage{hyperref} 
	\hypersetup{
	    colorlinks,
	    citecolor=black,
	    filecolor=black,
	    linkcolor=black,
	    urlcolor=blue
	}

% math packages
\usepackage{amsmath} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{mathtools}
\usepackage{cancel}
\usepackage{tikz}
\usetikzlibrary{patterns}
\usepackage[siunitx]{circuitikz}
	\sisetup{output-decimal-marker = {,}}
\usepackage{mhchem}
\tikzset{
    partial ellipse/.style args={#1:#2:#3}{
        insert path={+ (#1:#3) arc (#1:#2:#3)}
    }
}
\def\centerarc[#1](#2)(#3:#4:#5)% Syntax: [draw options] (center) (initial angle:final angle:radius)
    { \draw[#1] ($(#2)+({#5*cos(#3)},{#5*sin(#3)})$) arc (#3:#4:#5); }
 \usepackage{soul}
 
% upright math operators
\DeclareMathOperator{\lin}{lin}
\DeclareMathOperator{\sgn}{sgn}

% chapter localization
\addto\captionsserbian{\renewcommand{\contentsname}{Sadrzhaj}} 
\addto\captionsserbian{\renewcommand{\bibname}{Literatura}}
\addto\captionsserbian{\renewcommand{\indexname}{Indeks pojmova}} 
\addto\captionsserbian{%
  \renewcommand\appendixname{Dodatak}
  \renewcommand\appendixpagename{Dodatak}
}
\setlength{\marginparwidth}{2cm}
\usepackage[]{todonotes}
\renewcommand{\chaptername}{}

\makeatletter
\providecommand*{\diff}%
{\@ifnextchar^{\DIfF}{\DIfF^{}}}
\def\DIfF^#1{%
\mathop{\mathrm{\mathstrut d}}%
\nolimits^{#1}\gobblespace}
\def\gobblespace{%
\futurelet\diffarg\opspace}
\def\opspace{%
\let\DiffSpace\!%
\ifx\diffarg(%
\let\DiffSpace\relax
\else
\ifx\diffarg[%
\let\DiffSpace\relax
\else
\ifx\diffarg\{%
\let\DiffSpace\relax
\fi\fi\fi\DiffSpace}

% Define block styles
\tikzstyle{decision} = [diamond, draw, fill=gray, 
    text width=4.5em, text badly centered, node distance=3cm, inner sep=0pt]
\tikzstyle{block} = [rectangle, draw, fill=gray, 
    text width=10em, text centered, rounded corners, minimum height=4em]
\tikzstyle{line} = [draw, -latex']
\tikzstyle{cloud} = [draw, ellipse,fill=red!20, node distance=3cm,
    minimum height=2em]

% Glossaries
\usepackage[acronym]{glossaries}
\makeglossaries
\newacronym{MFKK}{MFKK}{mel-frekvencijski kepstralni koeficijenti}
\newacronym{DFT}{DFT}{diskretna Furijeova transformacija}
\newacronym{LBP}{$LBP$}{$Linear$ $Binary$ $Pattern$}
\newacronym{LSTM}{$LSTM$}{$Long$ $Short$-$Term$ $Memory$}
\newacronym{LBF}{$LBF$}{$Local$ $Binary$ $Features$}
\newacronym{3DMM}{$3DMM$}{$3D$ $Morphable$ $Model$}
\newacronym{AAM}{$AAM$}{$Active$ $Appearance$ $Model$}
\newacronym{PCA}{$PCA$}{$Principal$ $Component$ $Analysis$}
\newacronym{SFM}{$SFM$}{$Surrey$ $Face$ $Model$}
\newacronym{BPTT}{$BPTT$}{$Backpropagation$ $Trough$ $Time$}
\newacronym{TBPTT}{$TBPTT$}{$Truncated$ $Backpropagation$ $Trough$ $Time$}
\newacronym{BRNN}{$BRNN$}{$Bidirectional$ $Recurrent$ $Neural$ $Networks$}
\newacronym{RNN}{$RNN$}{$Recurrent$ $Neural$ $Networks$}
\newacronym{MSE}{$MSE$}{$Mean$ $Square$ $Error$}
\newacronym{API}{$API$}{$Application$ $Programming$ $Interface$}
\bibliographystyle{ieeetr}

\begin{document}
\thispagestyle{empty}

\begin{center}
    \begin{Large}
        Univerzitet u Beogradu -- Elektrotehnichki fakultet \\ \vspace{5pt}
    \end{Large}
\end{center}
\vspace{100pt}
\begin{center}
	\begin{huge} \textbf{MASTER RAD} \end{huge} \\ 
        \vspace{10pt}
        na temu \\
        \vspace{10pt}
    \begin{huge} 
        \textbf{Sinteza video zapisa} \\ \vspace{-2pt}
        \textbf{na osnovu govornog signala upotrebom} \\ \vspace{-2pt}
        \textbf{rekurentnih neuralnih mrezha} \\
    \end{huge} 
\end{center}
\vspace{200pt}
\begin{center}
	\begin{large}
		kandidat: \hfill  mentor: \\ \vspace{5pt}
		Veljko Sheshelj, 3253/2018 \hfill doc. dr Predrag Tadic1
	\end{large}
\end{center}
\vfill
\begin{center}	
avgust, 2020.
\end{center}

\chapter*{Zahvalnica}


\newpage
\tableofcontents



\chapter*{Uvod} 
\addcontentsline{toc}{chapter}{Uvod}
\markboth{Uvod}{Uvod}
Kompjuterska vizija je kompleksno polje koje se bavi procesiranjem slike i videa, odnosno ona omoguc1ava rachunarima da izvuku informaciju iz videa i slike. Postoji vec1 veliki broj tehnologija i aplikacija koji koriste kompjutersku viziju, poput autonomnih vozila, koji koriste analizu slike kako bi detektovali prepreke i znakove na putu, medicinskih sistema, koji koriste analizu slike kako bi se postavile dijagnoze, i prepoznavanja lica, koje koriste drushtvene mrezhe kako bi predlozhili ljude za oznachavanje na fotografiji. U komjutersku viziju spada i $deepfake$, grupa programa koji omoguc1avaju sintezu lazhnih videa (eng. $fake$) uz pomoc1 dubokih neuralnih mrezha (eng. $deep$ $neural$ $networks$). Otuda potiche i naziv $deepfake$. U ovom radu c1e biti predstavljen nachin na koji se mozhe dobiti lahni video osobe koja pricha iz audio signala govora, sa idejom da se karakteristichna obelezhja govornog signala transformishu u oblik usta koja osoba ima tokom izgovaranja tih glasova.\\
Dobijanje videa iz audio snimka ima veoma shiroku primenu. Osobina dobijanja videa visoke rezolucije iz audio snimka, znachajno bi smanjila protok potreban za kodiranje i transmisiju videa. Za ljude sa oshtec1enim sluhom, tehnika bi omoguc1ila kreiranje videa sa koga bi uspeshno mogli da chitaju sa usana. Takodje, nalaze veliku primenu u svetu video igara i filmskih efekata.\\
Preteche $deepfake$ programa zapochinju 1997. sa radom \cite{deepfake1}, u kome je razvijena inovativna tehnika koja je mogla da kreira nove kratke video animacije iz audio ulaza, generisanog iz teksta. Rad koristi ranije dostignuc1a za interpretaciju lica, generisanje audia iz teksta i $3D$ modela usta, ali je prvi koji je sve metode obuhvatio zajedno radi generisanja ubedljivog lazhnog videa. Ujedno, ovo istrazhivanje predstavlja i jedno od najznachajnijih za razvoj $deepfake$-a. Tokom 2000., kompjuterska vizija je napredovala u polju prepoznavanja lica. Razvoj u ovoj oblasti omoguc1io je bolje prac1enje pokreta lica, shto je prouzrokovalo ubedljivije rane $deepfake$ radove. Jedna takva metoda je \acrshort{AAM} algoritam koji statistichki modeluje oblik lica \cite{AAM}.\\ 
Mana ranijih radova je shto su zahtevali subjekta u laboratorisjkim uslovima gde se kontrolishu uslovi poput osvetljenosti lica, poze snimanja i teksta koje subjekt odgovara, kao i posedovanje skupe rachunarske i video opreme. Modeli su uglavnom bili statistichke prirode i nisu sadrzhali neauralne mrezhe. Za realizaciju ovog rada, bitno je da je baza podataka dostpuna na internetu i da se mozhe realizovati uz pomoc1 relativno jeftine komercijalno dostupne kompjuterske opreme. Ideja predstavljena u radu \cite{deepfake2} ispunjava te uslove. U radu se generishe lazhni video govora predsednika Baraka Obame iz audio snimka govora. Na internet sajtu $YouTube$ dostupno je oko $\SI{17}{h}$ video materijala predsednichkih obrac1anja naciji, snimljenog u periodu od 2008. do 2016. Videi su javno dostupni u visokoj rezoluciji i osvetljenje i pozicija glave se ne menjaju drastichno na njima. Uprkos dostpunosti takvih podataka, generisanje lazhnog videa je i dalje tezhak zadatak, najvishe zbog osetljivosti ljudskog oka na promene u regiji oko usta tokom govora neke osobe.\\
U ovom radu c1e se pokushati sa drugachijim nachinom dobijanja parametara koji predstavljaju oblik usta iz videa, kao i predstavic1e se modeli koji sadrzhe bidirekcione rekurentne mrezhe u svojim osnovama zarad dobijanja boljih rezultata pri obuchavanju. Akcenat rada c1e biti na samom obuchavanju razlichitih \acrshort{RNN} modela, ali bic1e i predstavljen jednostavan nachin dobijanja i samog videa.\\

\chapter{Obelezhja govora}\label{X}
Prvi korak u sintezi lazhnog videa iz govora je odredjivanje karakteristichnih obelezhja govornog signala. Komponentne audio signala treba da su dovoljno dobre da nose lingvistichku komponentu, ali i da su otporne na pozadinski shum i na ostale smetnje.
Jedna od osnovnih pretpostavki vezanih za obradu govornog signala jeste da se govor mozhe prikazati kao izlaz linearnog, vremenski promenljivog sistema, chija se svojstva sporo menjaju sa vremenom. To vodi ka osnovnom principu analize govora koji kazhe da ako se posmatraju dovoljno kratki segmenti govornog signala, da se tada svaki segment mozhe modelirati kao izlaz linearnog, vremenski invarijantnog sistema \cite{OPGpredavanja}. Stoga se kratki segmenti govora mogu opisati konvolucionom jednachinom
\begin{equation}\label{eq:1.1}
s(t) = e(t)*\theta(t)
\end{equation}
pri chemu $s(t)$ predstavlja rezultatni govorni signal, $e(t)$ predstavlja pobudnu vazdushnu struju (eksitaciju) i $\theta(t)$ impulsni odziv organa govornog trakta. U rachunarskoj obradi govora, signale je zgodnije posmatrati u diskretnom domenu
\begin{equation}
s[n] = e[n]*\theta[n]
\end{equation}
Zavisno od tipa eksitacije, govorni glasovi (fonemi) se mogu podeliti u tri distinktne kategorije:
\begin{itemize}[noitemsep]
\item zvuchni glasovi
\item frikativi (bezvuchni glasovi)
\item plozivi
\end{itemize}
Kod zvuchnih glasova, vazduh prelazi preko zategnutih glasnih zhica koje po\-chinju da vibriraju relaksiranim oscilacijama, proizvodec1i kvazi-periodichne chetvrtke koje c1e pobuditi vokalni trakt. Tipichni predstavnici zvuchnih glasova su samoglasnici. Pobuda koja proizvodi frikative je okarakterisana shirokim spektralnim sadrzhajem kao shto je sluchajni shum (glas \enquote{sh}). Plozivi nastaju pobudom koja je visokog inteziteta i kratkog trajanja (poput Dirakovog impulsa) (glasovi \enquote{b}, \enquote{p}, \enquote{t}...). Promenom oblika vokalnog trakta menja se frekvencijski sadrzhaj pobude i kao rezultat se dobijaju razlichiti fonemi. Engleski jezik razlikuje 42 fonema.\\
Problem govorne analize predstavlja odredjivanje parametara eksitacije i parametara implusnog odziva vokalnog trakta. Ovaj problem se mozhe nazvati i problemom razdvajanja konvolucionih komponenti, shto je poznato pod nazivom dekonvolucija.

\section{Kepstrum}
Kepstrum \cite{kepstrum} diskretnog signala $s[n]$ se mozhe izrachunati pomoc1u formule 
\begin{equation}
c_s[n] = \boldsymbol{\mathcal{F}^{-1}}(\log(|\boldsymbol{\mathcal{F}}(s[n])|)
\end{equation}
gde su sa $\boldsymbol{\mathcal{F}}$ i $\boldsymbol{\mathcal{F}^{-1}}$ oznachene \acrlong{DFT}(\acrshort{DFT}) i inverzna \acrshort{DFT}. Primenom \acrshort{DFT} na jednachinu \ref{eq:1.1} dobija se
\begin{equation}
S(f) = E(f)\cdot\Theta(f)
\end{equation}
Izrachunavanje kepstruma mozhe se smatrati sistemom za dekonvoluciju zbog chinjenice da logaritam proizvoda dve komponetne predstavlja zbir logaritmovanih komponenti
\begin{align}
\log|S(f)| &= \log|E(f)\cdot\Theta(f)|\\
           &= \log|E(f)| + \log|\Theta(f)|\\
           &= C_E(f)+ C_{\Theta}(f)
\end{align}
Primenom inverzne \acrshort{DFT} dobija se kepstrum govornog signala
\begin{align}
c_s[n] &= \boldsymbol{\mathcal{F}^{-1}}(C_E(f)+ C_{\Theta}(f))\\
       &= \boldsymbol{\mathcal{F}^{-1}}(C_E(f))+
       	  \boldsymbol{\mathcal{F}^{-1}}(C_{\Theta}(f))\\
       &= c_e[n]+ c_{\theta}[n]
\end{align}
U obliku signala $c_s[n]$ uochljive su oblasti u kojima dominiraju ekvivalenti vazdushne pobude  $c_e[n]$, odnosno impulsnog odziva govornih organa $c_{\theta}[n]$. Uticaj vazdushne pobude dominantniji je pri vec1im vrednostima argumenta, dok nizhe vrednosti argumenta nose informaciju o impulsnom odzivu vokalnog trakta. Zbog toga se najchesh\-c1e koristi prvih 12 kepstralnih koeficijenata, dok nulti koeficijent nosi informaciju o energiji signala.\\
Poshto je govor realan signal, amplituda spektra $|S(f)|$ je parna funkcija i kepstrum c1e imati realne vrednosti
\begin{align}
c_s[n] &= \boldsymbol{\mathcal{F}^{-1}}(\log(|\boldsymbol{\mathcal{F}}(s[n])|)\\
&=\frac{1}{N}\sum^{N-1}_{k=1}\log(|\boldsymbol{\mathcal{F}}(s[n])|)e^{\frac{j2kn\pi}{N}}\\
&=\frac{1}{N}\sum^{N-1}_{k=1}\log(|\boldsymbol{\mathcal{F}}(s[n])|)(\cos\left(\frac{2kn\pi}{N}\right)+j\sin\left(\frac{2kn\pi}{N}\right))\\
&=\frac{1}{N}\sum^{N-1}_{k=1}\log(|\boldsymbol{\mathcal{F}}(s[n])|)\cos\left(\frac{2kn\pi}{N}\right)
\end{align}
Zbog ovog svojstva, chesto se umesto inverzne \acrshort{DFT} koristi diskretna kosinusna transformacija radi smanjenja kompleksnosti izrachunavanja.

\section{Mel-frekvencijski kepstralni koeficijenti}
Prethodno opisani postupci se chesto koriste u primenama vezanim za automat\-sko prepoznavanje govora. U cilju oponashanja ljudskog nachina dozhivljavanja razlichitih uchestanosti u fonetima i primenjujuc1i kepstralnu analizu nastaju \acrlong{MFKK} (\acrshort{MFKK}). 
\subsection{Melova frekvencijska skala}
Mel-skala je uskladjena sa ljudskim osec1ajem visine glasa odnosno njegove uchestanosti. Njeno dobijanje se vrshi eksperimentalno, slushaocu se reprodukuje ton uchestanosti $\SI{1000}{Hz}$ i kao njegovo zapazhanje o visini ovog tona se belezhi vrednost $\SI{1000}{mel}$, i ova vrednost se koristi kao mera uporedjivanja za dalje dobijanje mel skale. Zatim se uchestanost povec1ava sve dok slushalac ne primeti ton koji slusha ima duplo vec1u visinu od uporedne vrednosti i ta visina oznachava vrednosh\-c1u od $\SI{2000}{mel}$. Ovaj se princip dobija za dobijanje ostalih vrednosti skale. Eksperimenti su ipak pokazali da je medjusobna zavisnost mela i herca lienarna do $\SI{500}{Hz}$, dok iznad ove uchestanosti jednakim promenama mela odgovara sve vec1a promena u hercima. Za konvertovanje frekvencije u melovu skalu i nazad mogu se koristiti formule
\begin{equation}\label{freq2mel}
M(f) = 1125\log\left(1+\frac{f}{700}\right)
\end{equation}
\begin{equation}\label{mel2freq}
M^{-1}(m) = 700\left(\exp\left(\frac{m}{1125}\right)-1\right)
\end{equation}

\subsection{Melova banka filtara}
Postojanje auditornih kritichnih opsega je takodje osobina koja uslovljava ljudski dozhivljaj razlichitih uchestanosti. Ova pojava vezana je za chujni dozhivljaj slushaoca  prilikom slushanja dva razlichita tona na razlichitim uchestanostima. Dakle, ukoliko se slushocu pusti ton uchestanosti $f_1$ koja se nalazi u nekom chujnom opsegu, tada slushalac ima dozhivljaj tona u skladu sa mel sklaom. Ukoliko se pored tog tona pusti drugi ton uchestanosti $f_2$ tada zvuchni dozhivljaj slushaoca zavisi od medjusobne frekventne bliskosti ova dva tona. Naime, ukoliko je frekventni razmak dovoljno mali tako da se nalaze unutar istog kritichnog chujnog opsega dolazi do pojave maskiranja i slushalac chuje ton $f_1$, ali vec1e glasnosti. Ukoliko je frekventni razmak ovih tonova vec1i od shirine chujnog kritichnog opsega tada slushalac chuje dva tona na odgovarajuc1im prethodno pomenutim uchestanostima. Imajuc1i to u vidu frekvencijski opseg govornog signala potrebno je izdeliti na opsege. Ti opsezi formiraju mel banku filtara. Postupak formitanja melove banke filtara se mozhe izdeliti na korake:
\begin{enumerate}
\item Koristec1i jendachinu \ref{freq2mel} konvertovati donju i gornju granicu govornog signala u melovu skalu. Za donju granicu se mozhe uzeti vrednost od $\SI{0}{Hz}$, dok je gornja frekvencija obichno uslovljena Nikvistovim kreiterijumom. U korish\-c1enom skupu podataka, govrni signal je odabiran sa $\SI{16}{kHz}$, pa je za gornju granicu korish\-c1ena vrednost od $\SI{8}{kHz}$.
\item Izdeliti opseg govornog signala na melovoj skali na ekvidistantne delove (opsege). Za broj delova se obichno uzima broj iz intervala $[26,\ 40]$. Za $n$ filtara dobijaju se $n+2$ frekvencije na melovoj skali.
\item Dobijene melove frekvencije, potrebno je vratiti u $\SI{}{Hz}$ frekvencije, formulom \ref{mel2freq}, koje se kasnije koriste za centralne uchestanosti trougaonih filtara
\end{enumerate}
\begin{figure}[h!]
\centering
  \includegraphics[scale=0.5]{res/10filterbank.png}
  \caption{Govorni frekvencijski opseg podeljen na 10 mel filtara}
  \label{fig:2}
  \vspace{0pt}
\end{figure}
\subsection{Algoritam izrachunavanja \acrshort{MFKK}}
U ovom poglavlju c1e biti prikazan detaljan postupak dobijanja \acrshort{MFKK}.
\begin{itemize}
\item \textbf{Visokofrekventno filtriranje}\\
Govorni signal je po prirodi analogni signal, koji je potrebno diskretizovati i digitalizovati da bi se izrachunala trazhena obelezhja. Pomenuti procesi su niskofrekventni i utichu na slabljenje vishih spektralnih komponenti u govornog signalu. Iz tog razloga nakon izvrshene digitalizacije, a pre samog izdvajanja obelezhja, potrebno je izvrshiti predobradu snimljenog govornog signala. To se postizhe primenom visokopropusnog filtra prvog reda
\begin{equation}
H(z) = 1-az^{-1}
\end{equation}
pri chemu se parametar $a$ bira iz intervala $[0.95,\ 0.98] $\cite{kepstrum}.
\item \textbf{Prozorovanje signala}\\
Na pochetku poglavlja je recheno da se samo kratki segmenti govora mogu smatrati kao izlaz linearnog, vremenski invarijantnog sistema. Sa tim u vezi signal je potrebno izdeliti na prozore duzhine $\SI{20}{ms}$-$\SI{40}{ms}$  \cite{OPGpredavanja}. U ovom radu izabrana je duzhina prozora od $\SI{25}{ms}$, sa preklapanjem izmedju susdenih prozora od $\SI{15}{ms}$. Naredni koraci se primenjuju za svaki prozor.
\item \textbf{Izrachunavanje spektra snage}\\
Za svaki prozor govornog signala je prvobitno potrebno odrediti \acrshort{DFT}. Radi potiskivanja bochnih lobova, zgodno je primeniti Hamingov prozor pre izrachunavanja \acrshort{DFT}. U ovom radu, \acrshort{DFT} za svaki prostor se izrachunava u 512 tachaka. Spektar snage se mozhe estimirati periodogramom, koji za signal $s[n]$ se izrachunava po formuli
\begin{align}
S(f) &=\boldsymbol{\mathcal{F}}(s[n])\\
P(f) &=\frac{1}{N}|S(f)|^2
\end{align}
\item \textbf{Filtriranje spektra snage melovom bankom filtara}\\
Dobijeni periodogram je potrebno filtrirati kroz svaki filtar iz melove banke. Dobijeni koeficijenti za svaki filtar se sumiraju. Na kraju se dobijaju koeficijenti koji nam govore koliko je energije sadrzhano u svakom filtru filter banke.
\item \textbf{Logaritmovanje}\\
Logaritmovati svaki koeficijent dobijen propushtanjem periodograma kroz banku filtara.
\item \textbf{Diskretna kosinusna transformacija}\\
Diskretnom kosinusnom transformacijom nad logaritmovanim energijama dobijaju se kepstralni koeficijenti.
\end{itemize}
\subsection{Dinamichka obelezhja}
Chesto je od interesa posmatrati i promenu \acrshort{MFKK} u vremenu \cite{kepstrum}. Na ovaj nachin, korish\-c1ena obelezhja direktno nose informaciju o promenama izmedju susednih prozora govornog signala. Radi izrachunavanja ovih obelezhja koriste se polinomijalne aproksimacije prvog i drugog izvoda kepstralnih koeficijenata \cite{MFKKlink}
\begin{align}
\Delta c_t &= \frac{\sum^{N}_{n=1}n(c_{t+n}-c_{t-n})}{2\sum^{N}_{n=1}n^2}\\
\Delta^2 c_t &= \frac{\sum^{N}_{n=1}n(\Delta_{t+n}-\Delta_{t-n})}{2\sum^{N}_{n=1}n^2}
\end{align}
gde su $\Delta c_t$ i $\Delta^2 c_t $ delta i delta-delta kepstralni koeficijenti za prozor $t$, izrachunati iz statichkih kepstralnih koeficijenata iz okolnih prozora. Tipichna vrednost koja se uzima je $N=2$.
\section{Prikaz obelezhja govora}
U ovom radu, kao vektor ulaznih parametara, korish\-c1eno je 13 kepstralnih koeficijenata, sa njihom deltama, shto daje ulazni vektor dimenzije 26. Umesto prvog kepstra, korish\-c1ena je energija signala. Iz baze video fajlova, samo audio snimci su izvucheni uz pomoc1 alata $FFmpeg$ \cite{FFmpeg}, chime se dobija baza audio snimaka govora predsednika Obame. Nakon toga, svaki audio fajl je normalizovan uz pomoc1 $FFmpeg-normalize$ dodatka \cite{FFmpegN}. Prikaz nekih kepstralnih koeficijenata, za nasumichno odabran audio snimak iz baze, se mozhe pogledati u nastavku.
\begin{figure}[h!]
\centering
  \includegraphics[scale=0.5]{res/audio_sig.png}
  \caption{Normalizovani audio signal nasumichno izabran iz baze}
  \label{fig:3}
  \vspace{0pt}
\end{figure}
\begin{figure}[!h]
        \centering
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.5]{res/cep1.png}
            \caption{Prvi \acrshort{MFKK}}
            \label{fig:4a}
            \vspace{0pt}
        \end{subfigure}%
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.5]{res/Dcep1.png}
            \caption{Delta prvog \acrshort{MFKK}}
            \label{fig:4b}
            \vspace{0pt}
        \end{subfigure}
		\vskip\baselineskip
        \centering
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.5]{res/cep6.png}
            \caption{Shesti \acrshort{MFKK}}
            \label{fig:5a}
            \vspace{0pt}
        \end{subfigure}%
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.5]{res/Dcep6.png}
            \caption{Delta shestog \acrshort{MFKK}}
            \label{fig:5b}
            \vspace{0pt}
        \end{subfigure}
		\vskip\baselineskip
        \centering
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.5]{res/cep12.png}
            \caption{Dvanaesti \acrshort{MFKK}}
            \label{fig:6a}
            \vspace{0pt}
        \end{subfigure}%
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.5]{res/Dcep12.png}
            \caption{Delta dvanaestog \acrshort{MFKK}}
            \label{fig:6b}
            \vspace{0pt}
        \end{subfigure}
        \caption{Prikaz glasovnih obelezhja}
        \label{fig:6}
\end{figure}

\chapter{Obelezhja videa}
U ovom poglavlju c1e biti objashnjen nachin na koji se iz video snimaka mozhe dobiti baza koja c1e sadrzhati koordinatne tachaka usta. Proces se mozhe podeliti na tri dela: detektovanje lica govornika na frejmu videa, detektovanje koordinata 68 znachajnih tachaka lica, pravljenje $3D$ modela lica iz kog c1e biti izdvajene $3D$ koordinate pojedinih tachaka usta. Kod korish\-c1enza generisanje obelezhja videa, kao i za generisanje slika dobijenih u nastavku mozhe se nac1i na linku \cite{gh1}.
\section{Detekcija lica}\label{detekcijalica}
Detekcija i prepoznavanje lica je jedna od najpopularnijih tema kompjuterske vizije u poslednjih nekoliko godina. Ova tehnologija je shiroko zastupljena, od kamera koje fokusiraju lica pre fotografisanja, do drushtvene mrezhe $Facebook$ koja prepoznaje  indetitet korisnika na slikama. Komjuterski program koji odlu\-chuje da li je slika pozitivna, odnosno da li postoji lice na njoj, ili negativna, odnosno da ne postoji, se naziva klasifikator. Klasifikator je obuchen na stotinama hiljada pozitivnih i negativnih slika, kako bi se nova slika klasifikovala ispravno. Biblioteka $OpenCV$ \cite{Opencv} nudi dva vec1 obuchena klasifikatora
\begin{itemize}
\item Harov\footnote{Alfred Har (1885. - 1933.)- madjarski matematichar } klafikator
\item \acrshort{LBP} klasifikator
\end{itemize}
U ovom radu je korish\-c1en Harov klasifikator, koji predstavlja efektivni metod detekcije objekata uz pomoc1 obelezhja i predstavljen je u radu \cite{Haar}. Inicijalno, algoritam krec1e od velike baze podataka pozitivnih i negativnih slika nad kojima ekstraktuje Harova obelezhja. Da bi se izrachunala Harova obelezhja, na svaku sliku se primenjuju konvolucioni kerneli sa slike \ref{fig:2_1}. Svako obelezhje se rachuna kao razlika sume vrednosti piksela ispod belog pravougaonika i sume vrednosti piksela ispod crnog pravougaonika.
\begin{figure}[h!]
\centering
  \includegraphics[scale=0.4]{res/haar_kernels.png}
  \caption{Konvolucioni kerneli za izrachunavanje Harovih obelezhja\protect\footnotemark}
  \label{fig:2_1}
  \vspace{0pt}
\end{figure}\\
\footnotetext{\fontencoding{T1}\selectfont\url{https://www.superdatascience.com/blogs/opencv-face-detection}}
Smisao metode se mozhe pokazati na primeru sa slike \ref{fig:2_2} gde se ekstraktuju dva obelezhja. Prvi se bazira na pojavi da je region oko ochiju chesto tamniji od regije nosa i obraza. Drugo oblezhje se bazira na tome shto su ochi tamnije od ivice nosa.
\begin{figure}[h!]
\centering
  \includegraphics[scale=0.6]{res/haar_features.png}
  \caption[Prikaz izrachunavanja dva Harova obelezhja]{Prikaz izrachunavanja dva Harova obelezhja \protect\footnotemark}
  \label{fig:2_2}
  \vspace{0pt}
\end{figure}\\
\footnotetext{\fontencoding{T1}\selectfont\url{https://docs.opencv.org/3.4/db/d28/tutorial_cascade_classifier.html}}
Za rachunanje svih obelezhja jedne slike koriste se svi moguc1i kerneli, u svim moguc1im velichinama na svakom delu slike, shto rezultuje velikim brojem obelezhja. Vec1ina oblezhja izrachunata ovakvom metodom je irelevantna. Algoritam koji se koristi za obuchavanje detektora lica i koji ima tu moguc1nost da razmatra samo najbitnija obelezhja je $Adaboost$. U svojoj originalnoj formi, $AdaBoost$ algoritam obuchavanja se koristi kako bi poboljshao klasifikaciju jednostavnih (slabih) algoritama obuchavanja. Za svako obelezhje, nadje se najbolji prag koji c1e klasifikovati slike na pozitivne i negativne  (panj odluchivanja kao slabi uchenik \cite{MUpredavanja}). Za rachunanje obelezhja na slikama, kernel je fiksne dimenzije $24\times24$. U svakoj iteraciji biraju se panjevi sa minimalnom greshkom, povec1avaju se tezhinski koeficijenti pogreshno klasifikovanih slika, smanjuju se tezhinski koeficijenti tachno klasifikovanih slika i rachuna se tezhina slabog uchenika. Nakon odredjenog broja iteracija, krajnji klasifikator predstavlja tezhinsku sumu slabih uchenika. Na kraju je dobijeno oko 6000 obelezhja.\\
Kako bi se dalje optimizovalo i unapredilo izrachunavanje obelezhjana slici, uvodi se pojam kaskadnog klasifikatora. Kaskadni klasifikator se sastoji od nekoliko nivoa, gde se svaki nivo sastoji od nekoliko panjeva odluchivanja. Svaki nivo oznachava region slike, odredjen trenutnom pozicijom pomerajuc1eg prozora, kao pozitivan ili negativan. U sluchaju da je region negativan, klasifikator prelazi na narednu lokaciju, a ako je region pozitivan, region prelazi na naredni nivo. Detektor prijavljuje da je lice u regionu detektovano u sluchaju da je region proshao sve nivoe. Nivoi su dizajnirani tako da odbace negativne regione shto brzhe, zbog pretpostavke da vec1ina regiona ne sadrzhi objekat od interesa, shto je u ovom sluchaju lice. Da bi metod dobro radio, svaki nivo mora da ima nizak broj lazhno negativnih detekcija. Ako nivo ne detektuje lice na regionu gde lice postoji, kaskadna klasifikacija se zaustavlja i greshka se ne mozhe otkloniti. Medjutim, svaki nivo sme imati visok broj lazhno pozitivnih detekcija, jer ukoliko detektor detektuje lice na regionu koji ne sadrzhi lice, greshka se mozhe ukloniti u narednim fazama. Dodavanje faza smanjuje broj lazhno pozitivnih detekcija, ali i smanjuje broj istinski pozitivnih detekcija.\\
Ovako obuchen klasifikator dostupan je uz $OpenCV$ biblioteku. U radu je odlucheno da se koristi Harov klasifikator, buduc1i da ima vec1u preciznost pri detekciji i umanjen broj lazhno pozitivnih detekcija, u odnosu na drugi dostupan \acrshort{LBP} klasifikator. Mana Harovog klasifikatora je shto je kompleksan i spor za izrachunavanje i manje precizan na tamnoputim licima. Buduc1i da se radi o predsedniku Obami, druga stavka je predstavljala potencijalan problem, ali nije primec1en neki znachajan broj frejmova na kojima lice nije detektovano. Tokom videa nedeljnih obrac1anja naciji, deshava se da kamerman nekoliko puta menja pozu i osvetljenje kojim snima govornika, u koliko se u nekom delu nije detektovalo lice taj deo videa bi bio preskochen. Takodje, na videima je prisutno samo jedno lice, i u sluchaju detekcije vishe lica, biralo bi se ono koje je najblizhe licu koje je detektovano u prethodnom frejmu.
\begin{figure}[!h]
        \centering
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.21]{res/168.jpg}
            \caption{168. frejm}
            \label{fig:2_3a}
            \vspace{0pt}
        \end{subfigure}%
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.21]{res/169.jpg}
            \caption{169. frejm}
            \label{fig:2_3b}
            \vspace{0pt}
        \end{subfigure}
        \vskip\baselineskip
        \centering
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.21]{res/170.jpg}
            \caption{170. frejm}
            \label{fig:2_3c}
            \vspace{0pt}
        \end{subfigure}%
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.21]{res/171.jpg}
            \caption{171. frejm}
            \label{fig:2_3d}
            \vspace{0pt}
        \end{subfigure}
        \caption{Prikaz detektovanih lica nad frejmovima videa $Weekly\ Address$: $A\ Balanced\ Approach\ to\ Growing\ the\ Economy\ in\ 2013$}
        \label{fig:2_3}
\end{figure}
\section{Detekcija karakteristichnih tachaka lica}
Detekcija karakteristichnih tachaka lica (eng. $facial\ landmarks$) je koristan algoritam potreban u razlichitim aplikacijama kao shto su prepoznavanje lica, prepoznavanje emocija na licima, zamena lica, prepoznavanje polozhaja glave, filteri na aplikacijama $Instagram$ i $Snapchat$... Krakateristichne tachke se koriste kako bi se lokalizovale i predstavile vidljive regije lica kao shto su ochi, obrve, nos, usta i vilica. Detekcija takvih tachaka predstavlja podskup problema u kojima je cilj predikcija nekog oblika. Prediktor oblika ima za cilj da na regiji od interesa slike lokalizuje kljuchne tachke duzh tog oblika. Stoga se ceo proces mozhe podeliti na dva dela, prvi koji c1e detektovati lice (poglavlje \ref{detekcijalica}) i detekcija kljuchnih tachaka.\\
Postoji veliki broj raspolozhivih detektora karakteristichnih tachaka lica, ali vec1ina njih se trudi da shto bolje detektuje sledec1e znachajne regije: usta, desna objva, leva obrva, desno oko, levo oko, nos i vilica. Detektor koji je dostupan uz biblioteku $OpenCV$ i koji je korish\-c1en u ovom radu je \acrshort{LBF} model (eng. \acrlong{LBF}, predstavljen u radu \cite{LBF}. Oblik lica $S=[x_1, y_1,...,x_{N_{fp}},y_{N_{fp}}]^T$ se sastoji od $N_{fp}$ karakteristichnih tachaka. Za datu sliku, cilj estimacije mozhe biti oblik $S$ koji c1e biti shto priblizhniji istinitom obliku $\hat{S}$ koji c1e minimizovati $||S-\hat{S}||$. Ova kriterijumska funkcija se najchesh\-c1e koristi u toku treniranja, kako bi se procenio performans. Autori rada \cite{LBF} koriste algoritam sluchajne shume kako bi odredili funkciju mapiranja tachaka na slici.
U zavisnosti koja je baza podataka korish\-c1ena pri treniranju, izlaz modela c1e imati drugachiji broj karakteristichnih tachaka na izlazu. Za \acrshort{LBF} model, korish\-c1en je $iBUG$ $300W$ set, koji sadrzhi slike sa ruchno oznachenim 68 tachaka.
\begin{figure}[h!]
\centering
  \includegraphics[scale=0.25]{res/facial_landmarks_68markup.jpg}
  \caption{Prikaz 68 karakteristichnih tachaka lica \protect\footnotemark}
  \label{fig:2_4}
  \vspace{0pt}
\end{figure}\\
\footnotetext{\fontencoding{T1}\selectfont\url{https://www.pyimagesearch.com/2017/04/03/facial-landmarks-dlib-opencv-python/}}
Od znachaja je primetiti da tachke koje predstavljaju usta imaju indekse od 49 do 68. Rezultate detekcije mozhete videti na narednim slikama.
\begin{figure}[!h]
        \centering
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.15]{res/168lm.jpg}
            \caption{168. frejm}
            \label{fig:2_5a}
            \vspace{0pt}
        \end{subfigure}%
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.15]{res/169lm.jpg}
            \caption{169. frejm}
            \label{fig:2_5b}
            \vspace{0pt}
        \end{subfigure}
        \vskip\baselineskip
        \centering
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.15]{res/170lm.jpg}
            \caption{170. frejm}
            \label{fig:2_5c}
            \vspace{0pt}
        \end{subfigure}%
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.15]{res/171lm.jpg}
            \caption{171. frejm}
            \label{fig:2_5d}
            \vspace{0pt}
        \end{subfigure}
        \caption{Prikaz detektovanih karakteristichnih tachaka lica nad frejmovima videa $Weekly\ Address$: $A\ Balanced\ Approach\ to\ Growing\ the\ Economy\ in\ 2013$}
        \label{fig:2_5}
\end{figure}
\newpage
\section[$3D$ model lica]{$\mathbf{3D}$ model lica}
$3D$  morfoloshki modeli  (eng. \acrlong{3DMM}- \acrshort{3DMM}) su moc1an alat u kompjuterskoj viziji. Oni imaju aplikaciju u zadacima gde se zahteva $2D$ procesiranje lica kao shto su, analiza lica, prepoznavanje, estimacija i normalizacija poze \footnote{Estimacija poze predstavlja zadatak da se na osnovu $3D$ modela i njegove slike, $2D$ projekcije, dobiju translacija i rotacija objekta takvi da daju tu $2D$ projekciju}. \acrshort{3DMM} su prvi put predlozhene u radu \cite{3DMM} i od tada se primenjuju u razlichitim zadacima. Medjutim, i dalje nisu toliko zastupljeni kao $2D$ metode, poput aktivnog modela izgleda \cite{AAM} (eng. \acrlong{AAM}- \acrshort{AAM}), iako imaju odredjene prednosti u odnosu na njih. U $3D$ modelu, poza lica je odvojena od oblika. Njegova projekcija u $2D$ je modelovana od strane modela fizichke kamere. Kamera model predstavlja funkciju koja mapira $3D$ prostor u prostor slike. Takodje, korish\-c1enje $3D$ modela omoguc1ava eksplicitno modelovanje izvora svetla, jer su informacije o povrshini i dubini objekta poznate. Model izvora svetla odvaja svetlost od izgleda lica i time jachina svetlosti ne utiche na parametre teksture, kao shto je sluchaj u \acrshort{AAM} modelima. Dalje, \acrshort{3DMM} mogu da se koriste kako bi se generisala specifichna lica, ili kako bi se generisali podaci za druge algoritme, jer pokrivaju razlichite poze, ukljuchujuc1i i ekstremne kao shto su pogledi iz profila. Ovo poslednje mozhe biti jako znachajno, u sluchaju da se tokom videa govora, menjaju uglovi iz kojih je govornik sniman na takav nachin da deo lica nije vidljiv. Sa druge strane, \acrshort{3DMM} su teshki za treniranje i zahtevaju dosta rachunarske snage za izrachunavanje.\\
Jedan \acrshort{3DMM} koji je dostupan na internetu je Sari \footnote{$University$ $of$ $Surrey$-univerzitet iz Velike Britanije} \acrshort{3DMM} model lica, koji je predstavljen u radu \cite{SFM}. Model se sastoji od tri nivoa rezolucije, od koji je samo najnizhi dostupan za nekomercijalne svrhe. Uz model, omoguc1ena je $C++$ biblioteka koja olakshava fitovanje poze i oblika na novim slikama (frejmovima) \cite{eos}.\\
Model se sastoji od dva \acrshort{PCA} modela \footnote{eng. \acrshort{PCA}- \acrlong{PCA}}: \acrshort{PCA} model oblika i \acrshort{PCA} model boje (teksture). Osnovna ideja \acrshort{PCA} metode, odnosno metode Karhunen-Loeve ekspanzije \cite{POpredavanja}, je da redukuje dimenziju vektora obelezhja radi uprosh\-c1avanja modela, a da gubitak informacija i preciznosti bude minimalan. Metoda smatra da se informacija krije u koordinatama velikih raspianja, odnosno varijansi. Lice se mozhe predstaviti kao vektor $S\in\mathbb{R}^{3N}$, koji sadrzhi $x$, $y$ i $z$ komponente oblika (vertekse), i vektora $T\in\mathbb{R}^{3N}$ koji nosi informaciju o $RGB$ boji svakog verteksa. Svaki \acrshort{PCA} model $\mathbf{M}$
\begin{equation}
\mathbf{M} = (\bar{\mathbf{v}}, \mathbf{\sigma}, \mathbf{V})
\end{equation}
se sastoji od komponenti $\bar{\mathbf{v}}\in\mathbb{R}^{3N}$, koji predstavljaju srednju vrednost $3D$ poligone mrezhe (eng. $polygonal$ $mesh$), skupa principijalnih komponenti $\mathbf{V}=[\mathbf{v}_1,...,\mathbf{v}_{n-1}]\in\mathbb{R}^{3N\times(n-1)}$ i standardne devijacije $\mathbf{\sigma}\in\mathbb{R}^{n-1}$, gde je $n$ broj $3D$ skenova koji su korish\-c1eni za pravljenje modela. Nova lica se mogu generisati izrachunavanjem
\begin{equation}
\mathbf{S} = \bar{\mathbf{v}}+\sum^M_i\mathbf{\alpha}_i\mathbf{\sigma}_i\mathbf{v}_i
\end{equation}
za oblik, gde je $M\le n-1$ je broj principjalnih komponenti i $\mathbf{\alpha}in\mathbb{R}^{M}$ su $3D$ koordinate nove instance u \acrshort{PCA} prostoru. Slichan metod se mozhe primeniti i za boju (albedo).\\
\acrshort{SFM} je izgradjen na velikom broju $3D$ skenova visoke rezolucije lica ljudi razlhite starosne dobi i razlhite boje kozhe. Vazhan podatak je da se u samom setu najmanje najmanje tamnoputih lica (oko $5\%$), ali zbog neposedovanja drugih \acrshort{3DMM} modela, odlucheno je da se ostane pri \acrshort{SFM}. 
\begin{figure}[h!]
\centering
  \includegraphics[scale=0.7]{res/Scan3DMM.png}
  \caption{Proces dobijanja jednog $3D$ skena za bazu podataka}
  \label{fig:2_6}
  \vspace{0pt}
\end{figure}\\
Iz skenova se formaraju vektori verteksa i vektori boja. U zavisnosti od nivoa rezolucije modela, ti vektori su razlichite dimenzije. Iz vektora verteksa i boja rachunaju se matrice kovarijanse iz kojih se chuvaju sopstveni vektori: 63 za oblik i 132 za boju.. Raspolozhiva biblioteka ukljuchuje metode potrebne za fitovanje poze, oblika i moguc1nost frontalizacije lica. Za dati set $2D$ karakteristichnih tachaka lica potrebo je znati u koje tachno vertekse model kamere slika te tachke, kao shto je to sluchaj za shiroko zastupljene $iBUG$ 68 karakteristichnih tachaka. U tom sluchaju, dobijanje modela kamere se svodi na reshavanje linearnog sistema jednachina. $3D$ koordinate oblika u \acrshort{PCA} prostoru $\mathbf{\alpha}$ se mogu nac1i minimizovanjem
\begin{equation}
\mathbb{E} = \sum^{3N}_i \frac{(y_{m2D,i}-y_i)^2}{2\mathbf{\sigma}^2_{2D}}+||\mathbf{\alpha}||
\end{equation}
gde je $N$ broj karakteristichnih tachaka, $y$ su detektovane ili oznachene karakteristichne tachke, $\mathbf{\sigma}^2_{2D}$ je opciona varijansa ovih karakteristihnih tachaka i $y_{m2D}$ je projekcija od \acrshort{3DMM} oblika u $2D$ dobijena korish\-c1enjem estimiranog modela kamere. Slichno se mozhe primeniti i za model teksture.
\begin{figure}[!h]
        \centering
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.3]{res/168_3D.jpg}
            \caption{168. frejm}
            \label{fig:2_7a}
            \vspace{0pt}
        \end{subfigure}%
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.3]{res/169_3D.jpg}
            \caption{169. frejm}
            \label{fig:2_7b}
            \vspace{0pt}
        \end{subfigure}
        \vskip\baselineskip
        \centering
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.3]{res/170_3D.jpg}
            \caption{170. frejm}
            \label{fig:2_7c}
            \vspace{0pt}
        \end{subfigure}%
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.3]{res/171_3D.jpg}
            \caption{171. frejm}
            \label{fig:2_7d}
            \vspace{0pt}
        \end{subfigure}
        \caption{Prikaz generisanih $3D$ modela lica iz frejmovima videa $Weekly\ Address$: $A\ Balanced\ Approach\ to\ Growing\ the\ Economy\ in\ 2013$}
        \label{fig:2_7}
\end{figure}\\
Korish\-c1enje date biblioteke zahteva dosta procerskog vremena. Uz pomoc1 kompajlerskih optimizacija dostupnim u okviru programskog jezika $C++$, smanjivanjem rezolucije videa na $480p$, $\SI{17}{h}$ video materijala je obradjeno za dve nedelje. Dobijen $3D$ model je zapisan u formatu $.obj$, koji predstavlja format koji se mozhe otvarati u programima poput $3D\ Paint$. Format $.obj$ je chitljiv tekstualni fajl \cite{obj} koji sadrzhi listu verteksa sa njihovim koordinatama, listu poligonalnih oblika koje ti verteksi formiraju, kao i informacije o teksturi svake poligonalne povrshi. Tekstura se chinformaciju o tome u koje se vertekse slika 68 karakteristichnih tachaka. Birajuc1i samo one vertekse koji predstavljaju $3D$ projekciju tachaka koji pripadaju regionu usta, dobija se 17 tachaka sa tri koordinate, shto daje izlazni vektor dimenzije 54.
\begin{table}[!h]
	\begin{center}
		\scalebox{0.6}{\begin{tabular}{||c|c||} 
 		\hline
 		Indeks tachke medju 68 karakteristichnih tachaka & Indeks verteksa u $3D$ modelu\\[0.5ex]
 		\hline\hline
 		49 & 398\\
 		\hline
 		50 & 315\\
 		\hline
 		51 & 413\\
 		\hline
 		52 & 329\\
 		\hline
 		53 & 825\\
 		\hline	
 		54 & 736\\
 		\hline	
 		55 & 812\\
 		\hline	
 		56 & 841\\
 		\hline	
 		57 & 693\\
 		\hline	
 		58 & 411\\
 		\hline	
 		59 & 264\\
 		\hline	
 		60 & 431\\
 		\hline	
 		61 & nije definisan\\
 		\hline	
 		62 & 416\\
 		\hline	
 		63 & 423\\
 		\hline	
 		64 & 828\\
 		\hline	
 		65 & nije definisan\\
 		\hline	
 		66 & 817\\
 		\hline	
 		67 & 442\\
 		\hline	
 		68 & 404\\
 		\hline	
		\end{tabular}}
	\end{center}
\caption{Mapiranje karakteristichnih tachaka usta na $3D$ model}
\label{tab:3_1}
\end{table}
\begin{figure}[h!]
\centering
  \includegraphics[scale=0.45]{res/verteksi.png}
  \caption{Prikaz odabranih verteksa}
  \label{fig:2_9}
  \vspace{0pt}
\end{figure}
\chapter{Rekurentne neuralne mrezhe}
Neuralne mrezhe su modeli uchenja koji ostvaraju ogroman uspeh u shirokom spektru zadataka superviziranog i nesuperviziranog mashinskog uchenja. Klasichne ($feedforward$) neuralne mrezhe se posebno izdvajaju u problemima klasifikacije. Uprkos njihovoj moc1i, standardne neuralne mrezhe imaju ogranichenja, od kojih je naznachajnije da primeri iz baze podataka moraju biti medjusobno nezavisni. U sluchaju kada su podaci zavisni u vremenu i prostoru ovo nije prihvatljivo. Frejmovi videa, delovi audio signala, rechi iz rechenice predstavljaju primere podataka gde zahtev o medjusobnoj nezavisnosti nije zadovoljen. Rekurentne neuralne mrezhe prevazilaze taj nedostatak i koriste se u sluchajevima kada se podaci mogu prikazati u formi sekvence. One imaju osobinu da selektivno prosledjuju informaciju izmedju koraka sekvence, dok i dalje procesuju jedan po jedan korak.\\
U ovom poglavlju c1e se prvo napraviti kratak osvrt na klasichne ($feedforward$) neuralne mrezhe, a zatim c1e biti detaljnije obradjen pojam razlichitih vrsta rekurentnih neuralnih mrezha.

\section{Pregled veshtachkih neuralnih mrezha}
Neuralne mrezhe su modeli izrachunavanja inspirasni bioloshkim neuralnim sistemom. Neuralna mrezha se sastoji od skupa veshtachkih neurona, koji se josh i nazivaju chvorovima, koji su medjusobno povezani sinapsama (vezama). Za svaki neuron $j$ se definishe funkcija aktivacije $l_j(*)$ i integraciona funkcija $f_j(*)$. Veza od chvora $j'$ ka chvoru $j$ je opisana tezhinskim koeficijentom $w_{jj'}$.
\begin{figure}[!h]
\hspace*{0.1\linewidth}
\begin{tikzpicture}
	\tikzstyle{rectangle_style}=[rectangle, draw]
	\tikzstyle{dividedrectangle_style}=[draw, rectangle split, rectangle split parts=2, rotate = 90, minimum height = 15mm, minimum width = 10mm]
	% neuron i
	\foreach \x in {0,...,2}
		\draw node at (0, -\x) [rectangle_style] (neuron_i_\x) {$v_\x$};
	\foreach \x in {1,...,3}
		\fill (0, -2.5 - \x*0.15) circle (1pt);
	\draw node at (0, -3.5) [rectangle_style] (neuron_i_3) {$v_i$};
	% w_ji
	\foreach \x in {0,...,2}
		\draw node at (1.5, -\x) [] (w_ji_\x) {$w_{j\x}$};
	\draw node at (1.5, -3.5) [] (w_ji_i) {$w_{ji}$};
	\foreach \x in {1,...,3}
		\fill (1.5, -2.5 - \x*0.15) circle (1pt);
	% neuron j
	\node at (6.5, -1.5) [dividedrectangle_style] (neuron_j){\rotatebox{-90}{$s_j = f_j (w_{ji}v_i)$} \nodepart{second} \rotatebox{-90}{$v_j = l_j (s_j)$}};
	% error
	\node at (10, -1.5) [] (error) {$v_j$};
	% connect: y_i -> w_ji
	\foreach \i in {0,...,2}
		\path[-] (neuron_i_\i) edge node[] {} (w_ji_\i);
	\path[-] (neuron_i_3) edge node[] {} (w_ji_i);
	\begin{scope}[decoration={
    markings,
    mark=at position 0.5 with {\arrow{>}}}
    ] 
	% connect: w_ji -> neuron j
	\foreach \i in {0,...,2}
		\draw[postaction={decorate}] (w_ji_\i) -- (neuron_j.north);
	\draw[postaction={decorate}] (w_ji_i)--(neuron_j.north);
	\end{scope}
	% connect: neuron j -> output
	\path[->] (neuron_j) edge node[above, midway] {$ $} (error);
\end{tikzpicture}
\caption{Shemat\-ski prikaz veshtachkog neurona}
\label{fig:7}
\end{figure}\\
Za integracionu funkciju se najchesh\-c1e uzima linearna suma, te se vrednost na izlazu jednog chvora mozhe izrachunati kao
\begin{equation}\label{node}
v_j = l_j\left(\sum^{i}_{k=0}w_{ji}v_i\right)
\end{equation}
Chesti izbori aktivacione funckije su sigmoid $\sigma(z)=1/(1+e^{-z})$ i hiperbolichki tangens $\tanh(z) = (e^z-e^{-z})/(e^z-e^{-z})$. Od skora, u modelima dubokih neuralnih mrezha koristi se aktivaciona funkcija $ReLU(z)=max(0,z)$ koja je pokazala zna\-chajno poboljshanje performansi.\\
$Feedforward$ neurlne mrezhe su vrsta veshtachkih neuralnih mrezha chiji usmereni grafovi ne smeju da sadrzhe petlje. Zbog odsustva petlji, chvorove  mrezhe je moguc1e organizovati u slojeve. Izlaz jednog sloja se dobija na osnovu izlaza nizhih slojeva.
\begin{figure}[h]
\begin{center}
    \begin{tikzpicture}
    	\tikzstyle{place}=[circle, draw=black, minimum size = 8mm]
    	
    	% Input
    	\foreach \x in {1,...,3}
    		\draw node at (0, -\x*1.25) [place] (first_\x) {$x_\x$};
    	\foreach \x in {1,...,3}
    		\fill (0, -4.5 -\x*0.3) circle (2pt);
    	\draw node at (0, -5*1.25) [place] (first_n) {$x_n$};
    	
    	% Hidden 1
    	\foreach \x in {1,...,3}
    		\node at (4, -\x*1.25) [place] (second_\x){$a_\x$};
    	\foreach \x in {1,...,3}
    		\fill (4, -4.5 -\x*0.3) circle (2pt);
    	\draw node at (4, -5*1.25) [place] (second_m) {$a_m$};
    	
    	% Output
	\foreach \x in {1,...,3}
    		\node at (8, -\x*1.25) [place] (fourth_\x){$y_\x$};
	\foreach \x in {1,...,3}
    		\fill (8, -4.5 -\x*0.3) circle (2pt);
    	\node at (8, -5*1.25) [place] (fourth_m) {$y_k$};
    		
    	% Input -> Hidden
    	\foreach \i in {1,...,3}
    		\foreach \j in {1,...,3}
    			\draw [->] (first_\i) to (second_\j);
    	\foreach \i in {1,...,3}
    		\draw [->] (first_\i) to (second_m);
    	\foreach \i in {1,...,3}
    		\draw [->] (first_n) to (second_\i);
	\draw [->] (first_n) to (second_m);
    	
    	% Hidden -> Output
    	\foreach \i in {1,...,3}
		\foreach \j in {1,...,3}
    			\draw [->] (second_\i) to (fourth_\j);
	\foreach \i in {1,...,3}
    		\draw [->] (second_\i) to (fourth_m);
    	\draw [->] (second_m) to (fourth_m);
    	
    	% Text
    	\node at (0, -8) [black, ] {Ulazni sloj};
    	\node at (4, -8) [black, ] {Skriveni sloj};
    	\node at (8, -8) [black, ] {Izlazni sloj};
    \end{tikzpicture}
    \caption{Shemtaski prikaz visheslojne $feedforward$ neuralne mrezhe}
    \label{fig:8}
\end{center}
\end{figure}\\
Vektor obelezhja $\mathbf{x}$ se dovodi na najnizhi (ulazni) sloj. Izlazi chvorova u narednim slojevima se sukcesivno izrachunavaju, dok se ne dobije izlaz najvisheg (izlaznog) sloja mrezhe $\mathbf{\hat{y}}$. $Feedforward$ mrezhe se koriste u supervizovanom uchenju na zadacima klasifikacije i regresije. Uchenje se ostvaruje azhuriranjem tezhinskih koeficijenata $w_{jj'}$ sa ciljem da se optimizuje kriterijumska funkcija $\mathfrak{L}(\mathbf{\hat{y}}, \mathbf{y})$, koja penalizuje distancu izmedju izlaznog vektora $\mathbf{\hat{y}}$ i vektora cilja $\mathbf{y}$.\\
Najuspeshniji algoritam za traniranje neuralnih mrezha je algoritam propagacije u nazad (eng. $backpropagation$)\cite{Backprog}. Algoritam propagacije u nazad koristi lanchano pravilo za rachunanje izvoda kriterijumske funkcije $\mathfrak{L}$. Tezhinski koeficijenti se popravljaju koristec1i algoritam gradijentnog spusta. Najchesh\-c1e korish\-c1en algoritam gradijentnog spusta je gradijentni spust koji koristi mini sharzhe (eng. $batch$) obuchavajuc1eg skupa. Taj algoritam kombinuje prednosti sharzhnog i stohastichkog gradijentnog spusta. Primenom tog algoritma koeficijenti se azhuriraju na osnovu akumulirane greshke svih primeraka iz mini sharzhe. Za sharzhu duzhine $n$ pravilo azhuriranja tezhinskih koeficijenata se mozhe zapisati ovako
\begin{equation}\label{SGD}
w := w- \eta\nabla_w\mathfrak{L}\left(\mathbf{\hat{y}^{i:i+n}}, \mathbf{y^{i:i+n}}\right)
\end{equation}
gde je sa $\eta$ oznachena brzina obuchavanja (eng. $learning\ rate$).
U opstem sluchaju, kriterijumska funkcija nije konveksna, i ne postoji garant da c1e gradijentni spust dovesti do globalnog minimuma. Mnoge varijante gradijentnog spusta se uvode kako bi se ubrzalo obuchavanje. Neke od najpopularnijih su: $AdaDelta$ \cite{AdaDelta}, $AdaGrad$ \cite{AdaGrad}, $RMSprop$ \cite{RMSprop} i $Adam$ \cite{Adam}. Uglavnom se zasnivaju na menjanju brzine obu\-chavanja kao i na momentumu koji predstavlja promenu tezhinskog koeficijenta u prethodnoj iteraciji algoritma.\\
Da bi se izrachunao gradijent u jednachini \ref{SGD} koristi se, vec1 pomenut, algoritam propagacije u nazad. Kao shto joj samo ime kazhe, algoritam zapochinje od izlaznog sloja i krec1e unazad ka nizhim slojevima. 
Za chvor $j$, koji se nalazi u izlaznom sloju, aktivacione funkcije $l_j(*)$ i linearnom integracionom funcijom $s_j(*)$, vazhi jednachina \ref{node}
\begin{align}
y_j=v_j &= l_j\left(s(w_{ji},v_i)\right)\\
&=l_j\left(\sum^{i}_{k=0}w_{ji}v_i\right)
\end{align}
Za tezhinski koeficijent veze izmedju chvora $j$ iz izlaznog sloja i cvora $i$ iz skrivenog sloja, promena se mozhe dobiti na sledec1i nachin
\begin{align}
\Delta w_{ji} &= -\eta\frac{\partial \mathfrak{L}\left(\mathbf{\hat{y}}, \mathbf{y}\right)}{\partial w_{ji}}\\
&=-\eta\left[\frac{\partial \mathfrak{L}\left(\mathbf{\hat{y}}, \mathbf{y}\right)}{\partial y_j}\right]\left[\frac{\partial y_j}{\partial s(w_{ji},v_i)}\right]\left[\frac{\partial s(w_{ji},v_i)}{\partial w_{ji}}\right]\\
&=\eta \delta_{ji}v_h\\
\delta_{ji} &=-\left[\frac{\partial \mathfrak{L}\left(\mathbf{\hat{y}}, \mathbf{y}\right)}{\partial y_j}\right]\left[\frac{\partial y_j}{\partial s(w_{ji},v_i)}\right] \label{delta}\\
&= -\left[\frac{\partial \mathfrak{L}\left(\mathbf{\hat{y}}, \mathbf{y}\right)}{\partial y_j}\right]l'_j(s_j)
\end{align}
Velichina $\delta_{ji}$ se naziva i signalom greshke. Prvi chinilac u izrazu \ref{delta} zavisi od izbora kriterijumske funkcije, a drugi predstavlja izvod aktivacione funkcije $l'_j(*)$. Za tezhinski koeficijent veze izmedju chvora koji pripada skrivenom sloju $i$ i chvora koji se nalazi u sloju iza $l$ vazhi
\begin{align}
\Delta w_{il} &= -\eta\frac{\partial \mathfrak{L}\left(\mathbf{\hat{y}}, \mathbf{y}\right)}{\partial w_{il}}\\
&=-\eta\left[\frac{\partial \mathfrak{L}\left(\mathbf{\hat{y}}, \mathbf{y}\right)}{\partial v_i}\right]\left[\frac{\partial v_i}{\partial s_l}\right]\left[\frac{\partial s_l}{\partial w_{il}}\right]\\
&=\eta \delta_{il}v_l\\
\delta_{il} &= l'_l(s_l)\sum_{k}\delta_{kl}w_{kl}\label{delta1}
\end{align}
Jednachina \ref{delta1} se sukcesivno primenjuje za sve nizhe slojeve, chime se uz sachuvane vrednosti izlaza chvorova dobijaju gradijenti pojedinachnih tezhinskih koeficijenata.

\section{Rani modeli rekurentnih neuralnih mrezha}
Rekurentne neuralne mrezhe su mrezhe chiji usmereni grafovi dozovljavaju petlje, chime se uvodi pojam vremena u model. U trenutku $t$, chvorovi sa rekurentnim vezama zavise od trenutnog ulaznog vektora $\mathbf{x}^{(t)}$ i vrednosti stanja chvora u prethodnom trenutku $\mathbf{h}^{(t-1)}$. Izlaz chvora $\mathbf{\hat{y}^{(t)}}$ zavisi od vrednosti stanja chvora $\mathbf{h}^{(t)}$ i, posredstvom rekurentnih veza, ulaza u trenutku $t-1$ 
$\mathbf{x}^{(t-1)}$ mozhe uticati na izlaz u trenutku $t$.
\newpage
\begin{figure}[!h]
\hspace*{0.1\linewidth}
\begin{tikzpicture}[item/.style={circle,draw,thick,align=center},
itemc/.style={item,on chain,join}]
 \begin{scope}[start chain=going right,nodes=itemc,every join/.style={-latex,very thick},local bounding box=chain]
 \path node (A0) {$\mathbf{h}^0$} node (A1) {$\mathbf{h}^{1}$} node (A2) {$\mathbf{h}^{2}$} node[xshift=2em] (At){$\mathbf{h}^{t}$};
 \end{scope}
 \node[left=1em of chain,scale=2] (eq) {$=$};
 \node[left=2em of eq,item] (AL) {$\mathbf{h}$};
 \path (AL.west) ++ (-1em,2em) coordinate (aux);
 \draw[very thick,-latex,rounded corners] (AL.east) -| ++ (1em,2em) -- (aux) 
 |- (AL.west);
 \foreach \X in {0,1,2,t} 
 {\draw[very thick,-latex] (A\X.north) -- ++ (0,2em)
 node[above,item,fill=gray!10] (h\X) {$\mathbf{y}^\X$};
 \draw[very thick,latex-] (A\X.south) -- ++ (0,-2em)
 node[below,item,fill=gray!10] (x\X) {$\mathbf{x}^\X$};}
 \draw[white,line width=0.8ex] (AL.north) -- ++ (0,1.9em);
 \draw[very thick,-latex] (AL.north) -- ++ (0,2em)
 node[above,item,fill=gray!10] {$\mathbf{y}^t$};
 \draw[very thick,latex-] (AL.south) -- ++ (0,-2em)
 node[below,item,fill=gray!10] {$\mathbf{x}^t$};
 \path (x2) -- (xt) node[midway,scale=2,font=\bfseries] {\dots};
\end{tikzpicture}
\caption{Shemat\-ski prikaz odmotane rekurentne neuralne mrezhe u vremenu}
\label{fig:9}
\end{figure}
Mrezha sa slike \ref{fig:9} se mozhe opisati jednachinama
\begin{align}
\mathbf{h}^t &= l_h(\mathbf{W_{hx}}\mathbf{x}^t+\mathbf{W_{hh}}\mathbf{h}^{t-1}+\mathbf{b_h})\label{RNN1}\\ 
\mathbf{y}^t &= l_y(\mathbf{W_{yh}}\mathbf{h}^t+\mathbf{b_y})\label{RNN2}
\end{align}
gde su sa $\mathbf{W_{hx}}$, $\mathbf{W_{yh}}$ i $\mathbf{W_{hh}}$ matrice koje sadrzhe tezhinske koeficijente, a $l_h$ i $l_y$ neke aktivacione funkcije. Vektori $b_h$ i $b_y$ omoguc1avaju uchenje ofseta.\\
Istrazhivanja na temu rekurentnih neuralnih mrezha su zapochela osadesetih godina proshloga veka. Prvo je Hopfild predstavio familiju rekurentnih neuralnih mrezha koja je imala moguc1nosti prepoznavanja shablona \cite{Hopfild}. Struktura mrezhe je ista kao na slici \ref{fig:9}, s tim da se ulazni shablon $\mathbf{x}$ primeni samo u pochetnom trenutku, nakon koga se mrezha prepusti izrachunavanjima  sve dok se na izlazu ne dobije stacionarna vrednost. Hopfildove mrezhe imaju moguc1nost da reprodukuje memorisane shablone iz zashumljenih shablona koje dobiju na ulazi i predstavljaju pretechu Bolcmanovih mashina i auto-enkodera.\\
Rani model za supervizovano uchenje sekvenci je predstavio D2ordan u \cite{jordan}. Model je $feedforward$ mrezha koja se sastoji od jednog skrivenog sloja koji sadrzhi specijalne chvorove. Izlaz mrezhe je vezama spojen sa specijalnim chvorovima, koji rekurentnim vezama, u narednom vremenskom trenutku, dostavljaju vrednosti ostalim chvorovima skrivenog sloja. U sluchaju da izlaz mrezhe predstavlja neke akcije, ovakav model omoguc1ava pamec1enje akcije iz prethodnog vremensog trenutka. Nekoliko modernih modela koristi ovu ideju. Jedan takav primerak je rad \cite{Sutskever} gde se na primeru prevodioca jezika, pri generisanju teksta prevedenih rechenica, rechi sa kraja se vrac1aju i koriste kao ulaz za naredni korak. Specijalni chvorovi mogu da sadrzhe i dodatnu rekurentnu vezu tako da za ulaz imaju i svoje prethodno stanje (slika \ref{fig:10}).\\
Elmanov model iz \cite{Elman} predstavlja arhitekturu koja lichi na mrezhu sa slike \ref{fig:9}. Za razliku od D2ordanovog modela, koji chuva trenutnu vrednost izlaza u specijalnim chvorovima, Elmanov model chuva trenutnu vrednost chvorova skrivenog sloja, koju u narednom vremenskom trenutku vrac1a tim skrivenim chvorovima (slika \ref{fig:11}). Elman je u svom radu trenirao mrezhu algoritmom propagacije u nazad i dokazao da mrezha mozhhe nauchiti zavisnosti od vremena.
\newpage
\begin{figure}[!h]
\hspace*{0.4\linewidth}
\begin{tikzpicture}[item/.style={circle,draw,thick,align=center}]
 \node[left=0,item, inner sep=2pt, minimum size=1cm] (AL) {$\mathbf{h}$};
 
 \draw[white,line width=0.8ex] (AL.north) -- ++ (0,1.9em);
 \draw[very thick,-latex] (AL.north) -- ++ (0,2em)
 node[above,item,fill=gray!10,inner sep=2pt, minimum size=1cm](y) {$\mathbf{y}^t$};
 \draw[very thick,latex-] (AL.south) -- ++ (0,-2em)
 node[below,item,fill=gray!10,inner sep=2pt, minimum size=1cm] {$\mathbf{x}^t$};
 
 \node[right=1cm, item,inner sep=2pt, minimum size=1cm](s) {$\mathbf{s}$};
 \draw[very thick,-latex, dotted] (s.west) to [out=-150,in=-30] (AL.east);
 \draw[very thick,-latex, red](y.east) to (s.north);
 \draw[very thick,-latex,dotted](s.east) to [out=0,in=-90,distance=2cm](s.south);
 \node[text width=4cm] at (5,2)(t1) {rekurentna veza};
 \draw [very thick,-latex,dotted] (2,2.05) to (3,2.05);
 \node[text width=4cm] at (5,1.5)(t2) {$\mathbf{W}=1$};
 \draw [very thick,-latex, red] (2,1.54) to (3,1.54);
\end{tikzpicture}
\vspace{0pt}
\caption{Shemat\-ski prikaz D2ordanovog modela}
\label{fig:10}
\end{figure}
\begin{figure}[!h]
\hspace*{0.4\linewidth}
\begin{tikzpicture}[item/.style={circle,draw,thick,align=center}]
 \node[left=0,item, inner sep=2pt, minimum size=1cm] (AL) {$\mathbf{h}$};
 
 \draw[white,line width=0.8ex] (AL.north) -- ++ (0,1.9em);
 \draw[very thick,-latex] (AL.north) -- ++ (0,2em)
 node[above,item,fill=gray!10,inner sep=2pt, minimum size=1cm](y) {$\mathbf{y}^t$};
 \draw[very thick,latex-] (AL.south) -- ++ (0,-2em)
 node[below,item,fill=gray!10,inner sep=2pt, minimum size=1cm] {$\mathbf{x}^t$};
 
 \node[right=1cm, item,inner sep=2pt, minimum size=1cm](s) {$\mathbf{s}$};
 \draw[very thick,-latex, dotted] (s.west) to [out=-120,in=-60] (AL.east);
 \draw[very thick,-latex, red](AL.east) to [out=60,in=120](s.west);
 \node[text width=4cm] at (5,2)(t1) {rekurentna veza};
 \draw [very thick,-latex,dotted] (2,2.05) to (3,2.05);
 \node[text width=4cm] at (5,1.5)(t2) {$\mathbf{W}=1$};
 \draw [very thick,-latex, red] (2,1.54) to (3,1.54);
\end{tikzpicture}
\vspace{0pt}
\caption{Shemat\-ski prikaz Elmanovog modela}
\label{fig:11}
\end{figure}
\section{Obuchavanje rekurentnih neuralnih mrezha}
Dok su u nachelu rekurentne neuralne mrezhe jednostavan i moc1an model, u praksi njihovo obuchavanje je kompleksan proces. Medju glavnim razlozima su problemi nestajuc1eg i eksplodirajuc1eg gradijenta, koji su predstavljeni u radu \cite{Bengio}. Kriterijumska funckija za rekurentnu neuralnu mrezhu predstavlja sumu gubitaka u pojedinachnim vremenskim trenucima. Ako je duzhina sekvence $T$, ona se rachuna 
\begin{equation}
\mathfrak{L}(\mathbf{\hat{y}},\mathbf{y}) = \sum^{T}_{t=1}\mathfrak{L}(\mathbf{\hat{y}},\mathbf{y})
\end{equation}
Radi optimizacije kriterijumske funckije i dalje se mozhe koristiti gradijenti spust, ali za rachunanje gradijenta potrebno je izmeniti algoritam propagacije u nazad. Modifikovan algoritam se naziva algoritam propagacije u nazad kroz vreme \cite{BPTT} (eng. \acrlong{BPTT}- \acrshort{BPTT}). Posmatrajmo jednostavnu rekurentnu mrezhu sa slike \ref{fig:9}, sa jednim skrivenim rekurentnim slojem. Za nju vazhe jednachine \ref{RNN1} i \ref{RNN2}.
\begin{align}
\mathbf{h}^t &= l_h(u_t)\\
\mathbf{y}^t &= l_y(\mathbf{o}^t)\\
\mathbf{o}^t &= \mathbf{W_{yh}}\mathbf{h}^t+\mathbf{b_y}\\
\mathbf{u}^t &= \mathbf{W_{hx}}\mathbf{x}^t+\mathbf{W_{hh}}\mathbf{h}^{t-1}+\mathbf{b_h} 
\end{align}
Jedna iteracija algoritma \acrshort{BPTT} se mozhe prikazati kroz sledec1e postupke:
\renewcommand{\labelenumii}{\arabic{enumii}.}
\begin{enumerate}
\item Inicijalizuju se vrednosti promena tezhinskih matrica i vektora odstupanja: $\Delta\mathbf{W}_{hx},\ \Delta\mathbf{W}_{hh},\ \Delta\mathbf{W}_{yh}, \Delta\mathbf{b}_h$  i $\Delta\mathbf{b}_y$ na nula vektore/matrice.
\item Za svaki trenutak $t$ od $T$ do 1:
\begin{enumerate}
\item  $\Delta\mathbf{o}^t \Leftarrow l'_y(\mathbf{o}^t)\frac{\partial\mathfrak{L}(\mathbf{\hat{y}},\mathbf{y})}{\partial\mathbf{\hat{y}}^t}$
\item $\Delta\mathbf{b}_y \Leftarrow \Delta\mathbf{b}_y+\Delta\mathbf{o}^t$
\item $\Delta\mathbf{W}_{yh} \Leftarrow \Delta\mathbf{W}_{yh}+\Delta\mathbf{o}^t(\mathbf{h}^t)^T$
\item $\Delta\mathbf{h}^t \Leftarrow \Delta\mathbf{h}^t+\mathbf{W}_{yh}^T\Delta\mathbf{o}^t$
\item $\Delta\mathbf{u}^t \Leftarrow l'_h(\mathbf{u}^t)\Delta\mathbf{h}^t$
\item $\Delta\mathbf{W}_{hx} \Leftarrow \Delta\mathbf{W}_{hx}+\Delta\mathbf{u}^t(\mathbf{v}^t)^T$
\item $\Delta\mathbf{b}_h \Leftarrow \Delta\mathbf{b}_h + \Delta\mathbf{u}^t$
\item $\Delta\mathbf{W}_{hh} \Leftarrow \Delta\mathbf{W}_{hh}+\Delta\mathbf{u}^t(\mathbf{h}^{t-1})^T$
\item $\Delta\mathbf{h}^{t+1} \Leftarrow \mathbf{W}_{hh}^T\Delta\mathbf{u}^t  $
\end{enumerate}
\item Dobijene vrednosti gradijenta iskoristiti za algoritam gradijentnog spusta.
\end{enumerate}
Posmatrajmo izvod
\begin{equation}\label{VG1}
\frac{\partial\mathfrak{L}(\mathbf{\hat{y}},\mathbf{y})}{\partial \mathbf{W}_{hh}} = \sum^{T}_{t=1}\Delta\mathbf{u}^t(\mathbf{h}^{t-1})^T
\end{equation}
Vrednost $\Delta\mathbf{u}^t $ se mozhe analitichki zapisati
\begin{equation}\label{VG2}
\Delta\mathbf{u}^t = \mathbf{W}_{yh}^T l'_y(\mathbf{o}^t)\frac{\partial\mathfrak{L}(\mathbf{\hat{y}},\mathbf{y})}{\partial\mathbf{\hat{y}}^t}\prod^T_{\tau=t+1}\mathbf{W}_{hh}^Tl'_h(\mathbf{u}^{\tau})
\end{equation}
Ako su sve sopstvene vrednosti matrice $\mathbf{W}_{yh}$ manje od 1 , onda c1e proizvod u jednachini \ref{VG2} sa povec1anjem broja chinilaca tezhiti nuli, i doprinos sumi u jednachini \ref{VG1} c1e tezhiti nuli. Drugim rechima greshka nec1e ispropagirati do nizhih vremenskih trenutaka, te se ovaj problem naziva problem nestajuc1eg gradijenta. Problem eksplodirajuc1eg gradijenta nastaje u sluchaju kada su sopstvene vrednosti matrice vec1 od 1, ali on mozhe da se regulishe izborom pogodnih aktivacionih funkcija i ogranichavanjem gradijenta pomoc1u regularizacije (eng. $gradient\ clipping$).\\
Jedno reshenje problema nestajuc1eg gradijenta je skrec1ena propagacija u nazad kroz vreme (eng. \acrlong{TBPTT}- \acrshort{TBPTT}) u kome se postavi broj koraka u kojima c1e greshka propagirati u nazad \cite{TBPTT}. Time se utiche na problem nestajuc1eg gradijenta, ali se onemoguc1uje uchenje duzhih vremenskih zavisnosti. Uchenje duzhih vremenskih zavisnosti omoguc1uju modernije arhitekture rekurentnih neuralnih mrezha.
\section{Moderne arhitekture rekurentnih neuralnih mrezha}
Najuspeshnija arhitektura rekurenntih neuralnih mrezha koja prevazilazi probleme obuchavanja duzhih vremenskih zavisnosti u sekvencama, predstaljena je u radu \cite{LSTM}. Ovaj model se naziva \acrlong{LSTM}- \acrshort{LSTM}. Drugi rad, \cite{BLSTM}, uvodi arhitekturu bidirekcionih rekurentnih neuralnih mrezha (eng. \acrlong{BRNN}- \acrshort{BRNN}), u kojoj informacija i iz proshlosti i iz buduc1nosti mozhe da se koristi da se odredi izlaz u svakom vremenskom trenutku. Ovo je u suprotnosti sa prethodnim radovima, u kojima su se samo ulazi iz proshlosti uticali na trenutni izlaz. Takodje, \acrshort{LSTM} i \acrshort{BRNN} je moguc1e kombinovati da bi se dobila $Bidirectional\ LSTM$ arhitektura.
\subsection[$LSTM$ model]{$\mathbf{LSTM}$ model}
$Hochreiter$ i $Schmidhuber$ u \cite{LSTM} su uveli \acrshort{LSTM} model primarno kako bi prevazishli problem nestajuc1eg graddijenta. Ovaj model predstavlja standardnu rekurentnu nuralnu mrezhu sa skrivenim slojem (slika \ref{fig:9}), ali klasichni chvor je zamenjen sa memorijskom c1elijom (slika \ref{LSTMcell}).
\begin{figure}[!h]
\hspace*{0.15\linewidth}
\newcommand{\empt}[2]{$#1^{\langle #2 \rangle}$}
\begin{tikzpicture}[
    % GLOBAL CFG
    font=\sf \scriptsize,
    >=LaTeX,
    % Styles
    cell/.style={% For the main box
        rectangle, 
        rounded corners=5mm, 
        draw,
        very thick,
        },
    operator/.style={%For operators like +  and  x
        circle,
        draw,
        inner sep=-0.5pt,
        minimum height =.2cm,
        },
    function/.style={%For functions
        ellipse,
        draw,
        inner sep=1pt
        },
    ct/.style={% For external inputs and outputs
        circle,
        draw,
        line width = .75pt,
        minimum width=1cm,
        inner sep=1pt,
        },
    gt/.style={% For internal inputs
        rectangle,
        draw,
        minimum width=4mm,
        minimum height=3mm,
        inner sep=1pt
        },
    mylabel/.style={% something new that I have learned
        font=\scriptsize\sffamily
        },
    ArrowC1/.style={% Arrows with rounded corners
        rounded corners=.25cm,
        thick,
        },
    ArrowC2/.style={% Arrows with big rounded corners
        rounded corners=.5cm,
        thick,
        },
    ]

%Start drawing the thing...    
    % Draw the cell: 
    \node [cell, minimum height =4cm, minimum width=6cm] at (0,0){} ;

    % Draw inputs named ibox#
    \node [gt] (ibox1) at (-2,-0.75) {$\sigma$};
    \node [gt] (ibox2) at (-1.5,-0.75) {$\sigma$};
    \node [gt, minimum width=1cm] (ibox3) at (-0.5,-0.75) {$tanh$};
    \node [gt] (ibox4) at (0.5,-0.75) {$\sigma$};

   % Draw opérators   named mux# , add# and func#
    \node [operator] (mux1) at (-2,1.5) {$\times$};
    \node [operator] (add1) at (-0.5,1.5) {$+$};
    \node [operator] (mux2) at (-0.5,0) {$\times$};
    \node [operator] (mux3) at (1.5,0) {$\times$};
    \node [function] (func1) at (1.5,0.75) {$tanh$};

    % Draw External inputs? named as basis c,h,x
    \node[ct, label={[mylabel]$Cell$}] (c) at (-4,1.5) {\empt{c}{t-1}};
    \node[ct, label={[mylabel]$Hidden$}] (h) at (-4,-1.5) {\empt{h}{t-1}};
    \node[ct, label={[mylabel]left:$Input$}] (x) at (-2.5,-3) {\empt{x}{t}};

    % Draw External outputs? named as basis c2,h2,x2
    \node[ct, label={[mylabel]right:$Cell$ ka $t+1$}] (c2) at (4,1.5) {\empt{c}{t}};
    \node[ct, label={[mylabel]right:$Hidden$ ka $t+1$}] (h2) at (4,-1.5) {\empt{h}{t}};
    \node[ct, label={[mylabel]left:$Output$}] (x2) at (2.5,3) {\empt{h}{t}};

% Start connecting all.
    %Intersections and displacements are used. 
    % Drawing arrows    
    \draw [ArrowC1, red] (c) -- (mux1) -- (add1) -- (c2);

    % Inputs
    \draw [ArrowC2] (h) -| (ibox4);
    \draw [ArrowC1] (h -| ibox1)++(-0.5,0) -| (ibox1); 
    \draw [ArrowC1] (h -| ibox2)++(-0.5,0) -| (ibox2);
    \draw [ArrowC1] (h -| ibox3)++(-0.5,0) -| (ibox3);
    \draw [ArrowC1] (x) -- (x |- h)-| (ibox3);

    % Internal
    \draw [->, ArrowC2] (ibox1) -- (mux1);
    \draw [->, ArrowC2] (ibox2) |- (mux2);
    \draw [->, ArrowC2] (ibox3) -- (mux2);
    \draw [->, ArrowC2] (ibox4) |- (mux3);
    \draw [->, ArrowC2] (mux2) -- (add1);
    \draw [->, ArrowC1] (add1 -| func1)++(-0.5,0) -| (func1);
    \draw [->, ArrowC2] (func1) -- (mux3);

    % Outputs
    \draw [-, ArrowC2] (mux3) |- (h2);
    \draw (c2 -| x2) ++(0,-0.1) coordinate (i1);
    \draw [-, ArrowC2] (h2 -| x2)++(-0.5,0) -| (i1);
    \draw [-, ArrowC2] (i1)++(0,0.2) -- (x2);
	
	% Legend
	\draw [ArrowC1,red] (3,-3) to (4,-3);
 	\node[text width=4cm] at (6.3,-3)(t2) {$\mathbf{W}=1$};
\end{tikzpicture}
\caption{\acrshort{LSTM} memorijska c1elija}
\label{LSTMcell}
\end{figure}\\
Kljuchna stvar u \acrshort{LSTM} chvoru je stanje c1elije (eng. $cell$ $state$) preko kog je omoguc1eno kretanje informacije bez promene. To se ostvaruje tako shto su tezhinski koeficijenti rekurentnih veza izmedju c1elijskih stanja fiksirani na 1. \acrshort{LSTM} ima moguc1nost da doda ili oduzme informacije iz stanja c1elije preko strukture koja se naziva $gate$. $Gate$ se sastoji od sigmoid aktivacione funkcije, koja se primenjuje na jedan vektor ulaza. Sigmoid funkcija ima vrednosti izmedju 0 i 1 i skalranim mnozhenjem sa drugim ulaznim vektorom se odlucjuje koliko se informacije tog drugog vektora prenosi dalje. \acrshort{LSTM} chvor sadrzhi tri $gate$-a.\\
\begin{itemize}
\item {$\mathbf{Input\ gate}$}\\
Ovaj $gate$ izrachunava kandidata za novo stanje c1elije. Sastoji se od dva dela (slika \ref{LSTM Input gate}). Prvi deo rachuna novog kandidata kojim c1e se azhuririati vrednost stanja c1elije $\tilde{C}_t$, a drugi deo $i_t$ odluchuje koji deo novog kandidata c1e se dodati na trenutno stanje c1elije.
\begin{align}
\mathbf{i}_t &= \sigma(\mathbf{W}_i[\mathbf{h}_{t-1}, \mathbf{x}_t]+\mathbf{b}_i)\\
\mathbf{\tilde{C}}_t &= \tanh(\mathbf{W}_C[\mathbf{h}_{t-1}, \mathbf{x}_t]+\mathbf{b}_c)
\end{align}
gde je sa $[\mathbf{h}_{t-1}, \mathbf{x}_t]$ oznachen zdruzheni vektor prethodnog izlaza c1elije i trenutnog vektora ulaza.
\begin{figure}[!h]
\hspace*{0.15\linewidth}
\newcommand{\empt}[2]{$#1^{\langle #2 \rangle}$}
\begin{tikzpicture}[
    % GLOBAL CFG
    font=\sf \scriptsize,
    >=LaTeX,
    % Styles
    cell/.style={% For the main box
        rectangle, 
        rounded corners=5mm, 
        draw,
        very thick,
        },
    operator/.style={%For operators like +  and  x
        circle,
        draw,
        inner sep=-0.5pt,
        minimum height =.2cm,
        },
    function/.style={%For functions
        ellipse,
        draw,
        inner sep=1pt
        },
    ct/.style={% For external inputs and outputs
        circle,
        draw,
        line width = .75pt,
        minimum width=1cm,
        inner sep=1pt,
        },
    gt/.style={% For internal inputs
        rectangle,
        draw,
        minimum width=4mm,
        minimum height=3mm,
        inner sep=1pt
        },
    mylabel/.style={% something new that I have learned
        font=\scriptsize\sffamily
        },
    ArrowC1/.style={% Arrows with rounded corners
        rounded corners=.25cm,
        thick,
        },
    ArrowC2/.style={% Arrows with big rounded corners
        rounded corners=.5cm,
        thick,
        },
    ]

%Start drawing the thing...    
    % Draw the cell: 
    \node [cell, minimum height =4cm, minimum width=6cm] at (0,0){} ;

    % Draw inputs named ibox#
    \node [gt] (ibox1) at (-2,-0.75) {$\sigma$};
    \node [gt] (ibox2) at (-1.5,-0.75) {$\sigma$};
    \node [gt, minimum width=1cm] (ibox3) at (-0.5,-0.75) {$tanh$};
    \node [gt] (ibox4) at (0.5,-0.75) {$\sigma$};

   % Draw opérators   named mux# , add# and func#
    \node [operator] (mux1) at (-2,1.5) {$\times$};
    \node [operator] (add1) at (-0.5,1.5) {$+$};
    \node [operator] (mux2) at (-0.5,0) {$\times$};
    \node [operator] (mux3) at (1.5,0) {$\times$};
    \node [function] (func1) at (1.5,0.75) {$tanh$};

    % Draw External inputs? named as basis c,h,x
    \node[ct, label={[mylabel]$Cell$}] (c) at (-4,1.5) {\empt{c}{t-1}};
    \node[ct, label={[mylabel]$Hidden$}] (h) at (-4,-1.5) {\empt{h}{t-1}};
    \node[ct, label={[mylabel]left:$Input$}] (x) at (-2.5,-3) {\empt{x}{t}};

    % Draw External outputs? named as basis c2,h2,x2
    \node[ct, label={[mylabel]right:$Cell$ ka $t+1$}] (c2) at (4,1.5) {\empt{c}{t}};
    \node[ct, label={[mylabel]right:$Hidden$ ka $t+1$}] (h2) at (4,-1.5) {\empt{h}{t}};
    \node[ct, label={[mylabel]left:$Output$}] (x2) at (2.5,3) {\empt{h}{t}};

% Start connecting all.
    %Intersections and displacements are used. 
    % Drawing arrows    
    \draw [ArrowC1] (c) -- (mux1) -- (add1) -- (c2);

    % Inputs
    
    \draw [ArrowC2] (h) -| (ibox4);
    \draw [ArrowC1] (h -| ibox1)++(-0.5,0) -| (ibox1);
    
    \draw [ArrowC1,very thick, red] (h -| ibox3)++(-0.5,0) -| (ibox3);
    \draw [ArrowC1,very thick, red] (x) -- (x |- h)-| (ibox3);
	\draw [ArrowC1,very thick, red] (h -| ibox2)++(-0.5,0) -| (ibox2);
	\draw [ArrowC1,very thick, red] (h.east) to (-2,-1.5);
    % Internal
    \draw [->, ArrowC2] (ibox1) -- (mux1);
    \draw [->, ArrowC2,very thick, red] (ibox2) |- (mux2);
    \draw [->, ArrowC2,,very thick, red] (ibox3) -- (mux2);
    \draw [->, ArrowC2] (ibox4) |- (mux3);
    \draw [->, ArrowC2,,very thick, red] (mux2) -- (add1);
    \draw [->, ArrowC1] (add1 -| func1)++(-0.5,0) -| (func1);
    \draw [->, ArrowC2] (func1) -- (mux3);

    % Outputs
    \draw [-, ArrowC2] (mux3) |- (h2);
    \draw (c2 -| x2) ++(0,-0.1) coordinate (i1);
    \draw [-, ArrowC2] (h2 -| x2)++(-0.5,0) -| (i1);
    \draw [-, ArrowC2] (i1)++(0,0.2) -- (x2);
\end{tikzpicture}
\caption{$Input\ gate$}
\label{LSTM Input gate}
\end{figure}
\item $\mathbf{Forget\ gate}$\\
Ovaj $gate$ odluchuje koliko c1e se informacije iz prethodnog c1elijskog stanja $\mathbf{C}_{t-1}$  zadrzhati. Treba napomenuti da je ovaj $gate$ dodat naknadno u radu \cite{forget gate}. Odluka se donosi na osnovu izlaza sigmoid funkcije koji posmatra zdruzheni vektor trenutnog ulaza i prethodnog izlaza.
\begin{equation}
\mathbf{f}_t = \sigma(\mathbf{W}_f[\mathbf{h}_{t-1}, \mathbf{x}_t]+\mathbf{b}_f)
\end{equation}
\begin{figure}[!h]
\hspace*{0.15\linewidth}
\newcommand{\empt}[2]{$#1^{\langle #2 \rangle}$}
\begin{tikzpicture}[
    % GLOBAL CFG
    font=\sf \scriptsize,
    >=LaTeX,
    % Styles
    cell/.style={% For the main box
        rectangle, 
        rounded corners=5mm, 
        draw,
        very thick,
        },
    operator/.style={%For operators like +  and  x
        circle,
        draw,
        inner sep=-0.5pt,
        minimum height =.2cm,
        },
    function/.style={%For functions
        ellipse,
        draw,
        inner sep=1pt
        },
    ct/.style={% For external inputs and outputs
        circle,
        draw,
        line width = .75pt,
        minimum width=1cm,
        inner sep=1pt,
        },
    gt/.style={% For internal inputs
        rectangle,
        draw,
        minimum width=4mm,
        minimum height=3mm,
        inner sep=1pt
        },
    mylabel/.style={% something new that I have learned
        font=\scriptsize\sffamily
        },
    ArrowC1/.style={% Arrows with rounded corners
        rounded corners=.25cm,
        thick,
        },
    ArrowC2/.style={% Arrows with big rounded corners
        rounded corners=.5cm,
        thick,
        },
    ]

%Start drawing the thing...    
    % Draw the cell: 
    \node [cell, minimum height =4cm, minimum width=6cm] at (0,0){} ;

    % Draw inputs named ibox#
    \node [gt] (ibox1) at (-2,-0.75) {$\sigma$};
    \node [gt] (ibox2) at (-1.5,-0.75) {$\sigma$};
    \node [gt, minimum width=1cm] (ibox3) at (-0.5,-0.75) {$tanh$};
    \node [gt] (ibox4) at (0.5,-0.75) {$\sigma$};

   % Draw opérators   named mux# , add# and func#
    \node [operator] (mux1) at (-2,1.5) {$\times$};
    \node [operator] (add1) at (-0.5,1.5) {$+$};
    \node [operator] (mux2) at (-0.5,0) {$\times$};
    \node [operator] (mux3) at (1.5,0) {$\times$};
    \node [function] (func1) at (1.5,0.75) {$tanh$};

    % Draw External inputs? named as basis c,h,x
    \node[ct, label={[mylabel]$Cell$}] (c) at (-4,1.5) {\empt{c}{t-1}};
    \node[ct, label={[mylabel]$Hidden$}] (h) at (-4,-1.5) {\empt{h}{t-1}};
    \node[ct, label={[mylabel]left:$Input$}] (x) at (-2.5,-3) {\empt{x}{t}};

    % Draw External outputs? named as basis c2,h2,x2
    \node[ct, label={[mylabel]right:$Cell$ ka $t+1$}] (c2) at (4,1.5) {\empt{c}{t}};
    \node[ct, label={[mylabel]right:$Hidden$ ka $t+1$}] (h2) at (4,-1.5) {\empt{h}{t}};
    \node[ct, label={[mylabel]left:$Output$}] (x2) at (2.5,3) {\empt{h}{t}};

% Start connecting all.
    %Intersections and displacements are used. 
    % Drawing arrows    
    \draw [ArrowC1, very thick, red] (c) -- (mux1) -- (add1);
	 \draw [ArrowC1] (add1) -- (c2);
    % Inputs
    
    \draw [ArrowC2] (h) -| (ibox4);
    \draw [ArrowC1,very thick, red] (h -| ibox1)++(-0.5,0) -| (ibox1);
    
    \draw [ArrowC1] (h -| ibox3)++(-0.5,0) -| (ibox3);
    \draw [ArrowC1] (x) -- (x |- h)-| (ibox3);
	\draw [ArrowC1] (h -| ibox2)++(-0.5,0) -| (ibox2);
	\draw [ArrowC1,very thick, red] (h.east) to (-2,-1.5);
	\draw [ArrowC1,very thick, red] (x.north) to (-2.5,-1.5);
    % Internal
    \draw [->, ArrowC2,very thick, red] (ibox1) -- (mux1);
    \draw [->, ArrowC2] (ibox2) |- (mux2);
    \draw [->, ArrowC2] (ibox3) -- (mux2);
    \draw [->, ArrowC2] (ibox4) |- (mux3);
    \draw [->, ArrowC2] (mux2) -- (add1);
    \draw [->, ArrowC1] (add1 -| func1)++(-0.5,0) -| (func1);
    \draw [->, ArrowC2] (func1) -- (mux3);

    % Outputs
    \draw [-, ArrowC2] (mux3) |- (h2);
    \draw (c2 -| x2) ++(0,-0.1) coordinate (i1);
    \draw [-, ArrowC2] (h2 -| x2)++(-0.5,0) -| (i1);
    \draw [-, ArrowC2] (i1)++(0,0.2) -- (x2);
\end{tikzpicture}
\caption{$Forget\ gate$}
\label{LSTM Forget gate}
\end{figure}
Novo stanje c1elije se dobija kombinacijom $forget\ gate$-a sa prethodnim stanjem c1elije i kombinacijom $input\ gate$-a sa kandidatom za novo stanje
\begin{equation}
\mathbf{C}_t = \mathbf{f}_t\cdot\mathbf{C}_{t-1}+\mathbf{i}_t\cdot\mathbf{\tilde{C}}_{t-1}
\end{equation}
\item $\mathbf{Output\ gate}$\\
Izlaz se rachuna na osnovu stanja c1elije koje se prvo propusti kroz $\tanh$, kako bi se vrednosti ogranichile na interval $[-1,\ 1]$, a zatim se taj vektor skalarno pomnozhi sa vektorom koji odluchuje koliko c1e se stanja c1elije proslediti na izlaz
\begin{align}
\mathbf{o}_t &= \sigma(\mathbf{W}_o[\mathbf{h}_{t-1}, \mathbf{x}_t]+\mathbf{b}_o)\\
\mathbf{h}_t &= \tanh(\mathbf{C}_{t})
\end{align}
\begin{figure}[!h]
\hspace*{0.15\linewidth}
\newcommand{\empt}[2]{$#1^{\langle #2 \rangle}$}
\begin{tikzpicture}[
    % GLOBAL CFG
    font=\sf \scriptsize,
    >=LaTeX,
    % Styles
    cell/.style={% For the main box
        rectangle, 
        rounded corners=5mm, 
        draw,
        very thick,
        },
    operator/.style={%For operators like +  and  x
        circle,
        draw,
        inner sep=-0.5pt,
        minimum height =.2cm,
        },
    function/.style={%For functions
        ellipse,
        draw,
        inner sep=1pt
        },
    ct/.style={% For external inputs and outputs
        circle,
        draw,
        line width = .75pt,
        minimum width=1cm,
        inner sep=1pt,
        },
    gt/.style={% For internal inputs
        rectangle,
        draw,
        minimum width=4mm,
        minimum height=3mm,
        inner sep=1pt
        },
    mylabel/.style={% something new that I have learned
        font=\scriptsize\sffamily
        },
    ArrowC1/.style={% Arrows with rounded corners
        rounded corners=.25cm,
        thick,
        },
    ArrowC2/.style={% Arrows with big rounded corners
        rounded corners=.5cm,
        thick,
        },
    ]

%Start drawing the thing...    
    % Draw the cell: 
    \node [cell, minimum height =4cm, minimum width=6cm] at (0,0){} ;

    % Draw inputs named ibox#
    \node [gt] (ibox1) at (-2,-0.75) {$\sigma$};
    \node [gt] (ibox2) at (-1.5,-0.75) {$\sigma$};
    \node [gt, minimum width=1cm] (ibox3) at (-0.5,-0.75) {$tanh$};
    \node [gt] (ibox4) at (0.5,-0.75) {$\sigma$};

   % Draw opérators   named mux# , add# and func#
    \node [operator] (mux1) at (-2,1.5) {$\times$};
    \node [operator] (add1) at (-0.5,1.5) {$+$};
    \node [operator] (mux2) at (-0.5,0) {$\times$};
    \node [operator] (mux3) at (1.5,0) {$\times$};
    \node [function] (func1) at (1.5,0.75) {$tanh$};

    % Draw External inputs? named as basis c,h,x
    \node[ct, label={[mylabel]$Cell$}] (c) at (-4,1.5) {\empt{c}{t-1}};
    \node[ct, label={[mylabel]$Hidden$}] (h) at (-4,-1.5) {\empt{h}{t-1}};
    \node[ct, label={[mylabel]left:$Input$}] (x) at (-2.5,-3) {\empt{x}{t}};

    % Draw External outputs? named as basis c2,h2,x2
    \node[ct, label={[mylabel]right:$Cell$ ka $t+1$}] (c2) at (4,1.5) {\empt{c}{t}};
    \node[ct, label={[mylabel]right:$Hidden$ ka $t+1$}] (h2) at (4,-1.5) {\empt{h}{t}};
    \node[ct, label={[mylabel]left:$Output$}] (x2) at (2.5,3) {\empt{h}{t}};

% Start connecting all.
    %Intersections and displacements are used. 
    % Drawing arrows    
    \draw [ArrowC1] (c) -- (mux1) -- (add1) -- (c2);
	 \draw [ArrowC1] (add1) -- (c2);
    % Inputs
    
    \draw [ArrowC2,very thick, red] (h) -| (ibox4);
    \draw [ArrowC1] (h -| ibox1)++(-0.5,0) -| (ibox1);
    
    \draw [ArrowC1] (h -| ibox3)++(-0.5,0) -| (ibox3);
    \draw [ArrowC1] (x) -- (x |- h)-| (ibox3);
	\draw [ArrowC1] (h -| ibox2)++(-0.5,0) -| (ibox2);
	\draw [ArrowC1,very thick, red] (h.east) to (0,-1.5);
	\draw [ArrowC1,very thick, red] (x.north) to (-2.5,-1.5);
    % Internal
    \draw [->, ArrowC2] (ibox1) -- (mux1);
    \draw [->, ArrowC2] (ibox2) |- (mux2);
    \draw [->, ArrowC2] (ibox3) -- (mux2);
    \draw [->, ArrowC2,very thick, red] (ibox4) |- (mux3);
    \draw [->, ArrowC2] (mux2) -- (add1);
    \draw [->, ArrowC1,very thick, red] (add1 -| func1)++(-0.5,0) -| (func1);
    \draw [->, ArrowC2,very thick, red] (func1) -- (mux3);

    % Outputs
    \draw [-, ArrowC2,very thick, red] (mux3) |- (h2);
    \draw (c2 -| x2) ++(0,-0.1) coordinate (i1);
    \draw [-, ArrowC2,very thick, red] (h2 -| x2)++(-0.5,0) -| (i1);
    \draw [-, ArrowC2,very thick, red] (i1)++(0,0.2) -- (x2);
\end{tikzpicture}
\caption{$Output\ gate$}
\label{LSTM Output gate}
\end{figure}
\end{itemize} 
\subsection[$BRNN$ model]{$\mathbf{BRNN}$ model}
U ovoj arhitekturi, postoje dva sloja chvorova u skrivenom sloju , i oba sloja su povezana sa ulaznim i izlaznim slojem. Jedan sloj ima rekurentne veze koje nose informaciju is proshlih vremenskih trenutaka, dok drugi nosi informaciju iz narednih vremenskih trenutaka. Za trenutak $t$ i ulazni vektor $\mathbf{x}_{t}$, stanja i izlaz mrezhe se mogu rachunati na sledec1i nachin
\begin{align}
\overrightarrow{\mathbf{h}}_t &= \sigma\left(\mathbf{W}^f_{hx}\mathbf{x}_t+\mathbf{W}^f_{hh}\overrightarrow{\mathbf{h}}_{t-1}+\mathbf{b}_h^f\right)\\
\overleftarrow{\mathbf{h}}_t &= \sigma\left(\mathbf{W}^b_{hx}\mathbf{x}_t+\mathbf{W}^b_{hh}\overleftarrow{\mathbf{h}}_{t-1}+\mathbf{b}_h^b\right)\\
\mathbf{\hat{y}}_t&= \sigma\left(\mathbf{W}^f_{yh}\overrightarrow{\mathbf{h}}_t +\mathbf{W}^b_{yh}\overleftarrow{\mathbf{h}}_t+\mathbf{b}_y\right) \label{eq:BRNN}
\end{align}
Sa datom ulaznom sekvencom, prvo se izrachunaju stanja $forward$ sloja $\overrightarrow{\mathbf{h}}_t$ pochevshi od prvog odbirka, a zatim se izrachunaju stanja $backward$ sloja $\overleftarrow{\mathbf{h}}_t$ pochevshi od poslednjeg odbirka sekvence. Nakon toga se, uz po jednachini \ref{eq:BRNN} izrachuna vektor izlaza. Za obuchavanje, mozhe se koristiti algoritam \acrshort{BPTT}. Jedna od mana \acrshort{BRNN} modela je shto se ne mozhe implementirati u realnom vremenu, jer je nemoguc1e saznati vrednost ulaznih odbiraka u buduc1nosti.
\newpage
\begin{figure}[!h]
\hspace*{0.2\linewidth}
\begin{tikzpicture}[item/.style={circle,draw,thick,align=center},
itemc/.style={item,on chain,join}]
 \begin{scope}[start chain=going right,nodes=itemc,every join/.style={-latex,very thick},local bounding box=chain]
 \path node (A0) {$\mathbf{h}_f^{0}$} node (A1) {$\mathbf{h}_f^{1}$} node (A2) {$\mathbf{h}_f^{2}$} node[xshift=2em] (At){$\mathbf{h}_f^{t}$};
 \end{scope}
 \foreach \X in {0,1,2,t} 
 {%\draw[very thick,-latex] (A\X.north) -- ++ (0,4em)
  %node[above,item,fill=gray!10] (hb\X) {$\mathbf{h}^\X$};
  \node[item] (hb\X) at ($(A\X.north)+(0,1)$) {$\mathbf{h}_b^\X$};
  \draw[very thick,-latex] (hb\X.north) -- ++ (0,2em)
        node[above,item,fill=gray!10] (y\X) {$\mathbf{y}^\X$};
  \draw[very thick,latex-] (A\X.south) -- ++ (0,-2em)
 		node[below,item,fill=gray!10] (x\X) {$\mathbf{x}^\X$};
  \draw[very thick,-latex](A\X.west) to [out=120,in=-120](y\X.west);}
 \path (x2) -- (xt) node[midway,scale=2,font=\bfseries] {\dots};
 \draw[very thick, latex-] (hb0) --++ (hb1);
 \draw[very thick, latex-] (hb1) --++ (hb2);
 \draw[very thick, latex-] (hb2) --++ (hbt);
\end{tikzpicture}
\caption{Shemat\-ski prikaz odmotane bidirekcione rekurentne neuralne mre\-zhe u vremenu}
\label{fig:12}
\end{figure}
Bidirekcione mrezhe mogu da se kombinuju sa \acrshort{LSTM} modelom tako shto se umesto obichnih \acrshort{RNN} chvorova koriste \acrshort{LSTM} c1elije.
\chapter{Rezultati obuchavanja modela}
U ovom poglavlju c1e biti predstavljeni razultati obuchavanja razlichitih modlea rekurentnih neuralnih mrezha.\\
Obelezhja govora i obelezhja videa se koriste kao ulazne i izlazne sekvence predlozhenih rekurentnih neuralnih mrezha. Obelezhja su dobijena iz $\SI{17}{h}$ dugog video materijala dostupnog na sajtu $YouTube$. Videi predstavljaju nedeljna obrac1anja naciji predsednika Obame, u periodu od 2009. do 2016. godine. Videi su morali biti u manjoj rezoluciji, $480p$, kako bi izdvajanje oblika usta bilo uradjeno u razumnom periodu.\\
U poglavlju \ref{X} je objash\-njen nachin na koji se dolazi do ulazne sekvence. Mozhe se primetiti da je perioda izmedju dva vektora ulazne sekvence, vec1a od periode izmedju dva vektora sekvence izlaza. Perioda izmedju dva \acrshort{MFKK} je uslovljena duzhinom prozora na koje se dele audio signali, kao i duzhinom preklapanja dva susedna prozora, dok je perioda izmedju dva oblika usta uslovljena brojem frejmova u sekudni videa. Stoga je potrebno  izvrshiti interpolaciju izlaznih sekvenci, kako bi se ulazne i izlazne sekvence svele na istu periodu. Pored toga, obelezhja govora se normalizuju. Radi potreba obuchavanja, celokupan set sekvenci se deli na trenirajuc1i i validacioni skup, gde $20\%$ sekvenci.\\
Svi modeli su realizovani uz pomoc1 biblioteke $TensorFlow$ \cite{TF}, gde je korish\-c1en $Keras$ $API$. Prelozheni su razlichiti \acrshort{LSTM} i \acrshort{BRNN} modeli, za chije obuchavanje je izabran $Adam$ \cite{Adam} optimizator. Za vrednost brzine obuchavanja $\alpha$ uzeta je vrednost $0.01$. Radi sprechavanja problema eksplodirajuc1eg gradijenta, za gradijent za sve parametre gradijent se klipuje na vrednost 100. Za kriterijumsku funkciju je uzeta srednja kvadratna greshka (\acrshort{MSE}). Hardverske specifikacije rachunara na kome je izvrsheno obuchavanje modela su: procesor $Intel$ $i5$-$8300H$ sa $\SI{16}{GB}$ $RAM$ memorije i grafichkom karticom $NVIDIA$ $GeForce$ $1050Ti$ sa $\SI{4}{GB}$ memorije. Vreme treniranja modela zavisi od komplesnosti modela, ali u proseku za 20 epoha je potrebno nekoliko sati.

\section[$LSTM$ modeli]{$\mathbf{LSTM}$ modeli}
U ovom delu bic1e prikazani razultati obuchavanja \acrshort{LSTM} modela. Parametar koji varira je dimenzija stanja c1elije $n$ u intervalu od 20 do 150. Prvobitno je pokushano sa jednim slojem skrivenih rekuretnih \acrshort{LSTM} c1elija, a kasnije i sa visheslojnim mrezhama. Generalno, ovakvi modeli su zasenjeni performansom \acrshort{BRNN}. Dodavanje slojeva nije pokazalo znachajnije poboljshanje, ali vreme potrebno za treniranje je znachajno produzheno.
\newpage
\begin{figure}[!h]
        \centering
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.45]{res/SingleLayerLSTM_30units_train.png}
            \caption{\acrshort{MSE} na trenirajuc1em skupu}
            \label{fig:4_1a}
            \vspace{0pt}
        \end{subfigure}%
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.45]{res/SingleLayerLSTM_30units_validation.png}
            \caption{\acrshort{MSE} na validacionom skupu}
            \label{fig:4_1b}
            \vspace{0pt}
        \end{subfigure}
        \caption{Jednoslojna \acrshort{LSTM} mrezha sa $n=30$}
        \label{fig:4_1}
\end{figure}
\begin{figure}[!h]
        \centering
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.45]{res/SingleLayerLSTM_60units_train.png}
            \caption{\acrshort{MSE} na trenirajuc1em skupu}
            \label{fig:4_2a}
            \vspace{0pt}
        \end{subfigure}%
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.45]{res/SingleLayerLSTM_60units_validation.png}
            \caption{\acrshort{MSE} na validacionom skupu}
            \label{fig:4_2b}
            \vspace{0pt}
        \end{subfigure}
        \caption{Jednoslojna \acrshort{LSTM} mrezha sa $n=60$}
        \label{fig:4_2}
\end{figure}
\begin{figure}[!h]
        \centering
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.45]{res/SingleLayerLSTM_90units_train.png}
            \caption{\acrshort{MSE} na trenirajuc1em skupu}
            \label{fig:4_3a}
            \vspace{0pt}
        \end{subfigure}%
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.45]{res/SingleLayerLSTM_90units_validation.png}
            \caption{\acrshort{MSE} na validacionom skupu}
            \label{fig:4_3b}
            \vspace{0pt}
        \end{subfigure}
        \caption{Jednoslojna \acrshort{LSTM} mrezha sa $n=90$}
        \label{fig:4_3}
\end{figure}
\newpage
\begin{figure}[!h]
        \centering
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.45]{res/SingleLayerLSTM_120units_train.png}
            \caption{\acrshort{MSE} na trenirajuc1em skupu}
            \label{fig:4_4a}
            \vspace{0pt}
        \end{subfigure}%
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.45]{res/SingleLayerLSTM_120units_validation.png}
            \caption{\acrshort{MSE} na validacionom skupu}
            \label{fig:4_4b}
            \vspace{0pt}
        \end{subfigure}
        \caption{Jednoslojna \acrshort{LSTM} mrezha sa $n=150$}
        \label{fig:4_4}
\end{figure}
\begin{figure}[!h]
        \centering
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.45]{res/SingleLayerLSTM_150units_train.png}
            \caption{\acrshort{MSE} na trenirajuc1em skupu}
            \label{fig:4_5a}
            \vspace{0pt}
        \end{subfigure}%
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.45]{res/SingleLayerLSTM_150units_validation.png}
            \caption{\acrshort{MSE} na validacionom skupu}
            \label{fig:4_5b}
            \vspace{0pt}
        \end{subfigure}
        \caption{Jednoslojna \acrshort{LSTM} mrezha sa $n=150$}
        \label{fig:4_5}
\end{figure}
\section[$BRNN$ modeli]{$\mathbf{BRNN}$ modeli}
U ovom delu c1e biti prikazani rezultati \acrshort{BRNN} modela, koji za rekurentne chvorove imaju \acrshort{LSTM} c1elije. Mozhe se primetiti da ove mrezhe imaju znachajno bolji uchinak od obichnih \acrshort{LSTM} mrezha. To se mozhe opravdati zapazhanjem da chovek dok govori, unapred zna koja su naredni foneti u okviru jedne rechi i tako buduci fonemi utichu na trenutni polozhaj usta. 
\newpage
\begin{figure}[!h]
        \centering
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.45]{res/SL_BLSTM_30units_d00_train.png}
            \caption{\acrshort{MSE} na trenirajuc1em skupu}
            \label{fig:4_6a}
            \vspace{0pt}
        \end{subfigure}%
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.45]{res/SL_BLSTM_30units_d00_validation.png}
            \caption{\acrshort{MSE} na validacionom skupu}
            \label{fig:4_6b}
            \vspace{0pt}
        \end{subfigure}
        \caption{Jednoslojna \acrshort{BRNN} mrezha sa $n=30$}
        \label{fig:4_6}
\end{figure}
\begin{figure}[!h]
        \centering
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.45]{res/SL_BLSTM_60units_d00_train.png}
            \caption{\acrshort{MSE} na trenirajuc1em skupu}
            \label{fig:4_7a}
            \vspace{0pt}
        \end{subfigure}%
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.45]{res/SL_BLSTM_60units_d00_validation.png}
            \caption{\acrshort{MSE} na validacionom skupu}
            \label{fig:4_7b}
            \vspace{0pt}
        \end{subfigure}
        \caption{Jednoslojna \acrshort{BRNN} mrezha sa $n=60$}
        \label{fig:4_7}
\end{figure}
\begin{figure}[!h]
        \centering
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.45]{res/SL_BLSTM_90units_d00_train.png}
            \caption{\acrshort{MSE} na trenirajuc1em skupu}
            \label{fig:4_8a}
            \vspace{0pt}
        \end{subfigure}%
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.45]{res/SL_BLSTM_90units_d00_validation.png}
            \caption{\acrshort{MSE} na validacionom skupu}
            \label{fig:4_8b}
            \vspace{0pt}
        \end{subfigure}
        \caption{Jednoslojna \acrshort{BRNN} mrezha sa $n=90$}
        \label{fig:4_8}
\end{figure}
\newpage
\begin{figure}[!h]
        \centering
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.45]{res/SL_BLSTM_120units_d00_train.png}
            \caption{\acrshort{MSE} na trenirajuc1em skupu}
            \label{fig:4_9a}
            \vspace{0pt}
        \end{subfigure}%
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.45]{res/SL_BLSTM_120units_d00_validation.png}
            \caption{\acrshort{MSE} na validacionom skupu}
            \label{fig:4_9b}
            \vspace{0pt}
        \end{subfigure}
        \caption{Jednoslojna \acrshort{BRNN} mrezha sa $n=120$}
        \label{fig:4_9}
\end{figure}
\begin{figure}[!h]
        \centering
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.45]{res/SL_BLSTM_150units_d00_train.png}
            \caption{\acrshort{MSE} na trenirajuc1em skupu}
            \label{fig:4_10a}
            \vspace{0pt}
        \end{subfigure}%
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.45]{res/SL_BLSTM_150units_d00_validation.png}
            \caption{\acrshort{MSE} na validacionom skupu}
            \label{fig:4_10b}
            \vspace{0pt}
        \end{subfigure}
        \caption{Jednoslojna \acrshort{BRNN} mrezha sa $n=150$}
        \label{fig:4_10}
\end{figure}
Sa slika \ref{fig:4_7b}, \ref{fig:4_8b} i \ref{fig:4_9b} se vidi da su modeli skloni preobuchavanju. Najjednostavniji nachin za reshavanje ovog problema je $dropout$ regularizacija, kojom se sa zadatom verovatnoc1om jedan chvor deaktivira i njegov se izlaz ne uzima tokom obuchavanja \cite{dropout}. $Keras$ nudi jednostavnu implementaciju ove regularizacije uz samo definisanje \acrshort{LSTM} chvora u programu. Vrednost $dropout$ verovatnoc1e ne treba da bude prevelika, kako se ne bi drastichno pokvarili rezultati obuchavanja, a ni premala kako bi efekat otklanjanja preobuchavanja bio primetan. Obuchavanje je ponovljeno sa $dropout$ verovatnoc1om $0.1$.
\newpage
\begin{figure}[!h]
        \centering
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.43]{res/SL_BLSTM_30units_d01_train.png}
            \caption{\acrshort{MSE} na trenirajuc1em skupu}
            \label{fig:4_11a}
            \vspace{0pt}
        \end{subfigure}%
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.43]{res/SL_BLSTM_30units_d01_validation.png}
            \caption{\acrshort{MSE} na validacionom skupu}
            \label{fig:4_11b}
            \vspace{0pt}
        \end{subfigure}
        \caption{Jednoslojna \acrshort{BRNN} mrezha sa $n=30$ i verovatnoc1om $dropout$ regularizacije $0.1$}
        \label{fig:4_11}
\end{figure}
\begin{figure}[!h]
        \centering
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.43]{res/SL_BLSTM_60units_d01_train.png}
            \caption{\acrshort{MSE} na trenirajuc1em skupu}
            \label{fig:4_12a}
            \vspace{0pt}
        \end{subfigure}%
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.43]{res/SL_BLSTM_60units_d01_validation.png}
            \caption{\acrshort{MSE} na validacionom skupu}
            \label{fig:4_12b}
            \vspace{0pt}
        \end{subfigure}
        \caption{Jednoslojna \acrshort{BRNN} mrezha sa $n=60$ i verovatnoc1om $dropout$ regularizacije $0.1$}
        \label{fig:4_12}
\end{figure}
\begin{figure}[!h]
        \centering
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.43]{res/SL_BLSTM_90units_d01_train.png}
            \caption{\acrshort{MSE} na trenirajuc1em skupu}
            \label{fig:4_13a}
            \vspace{0pt}
        \end{subfigure}%
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.43]{res/SL_BLSTM_90units_d01_validation.png}
            \caption{\acrshort{MSE} na validacionom skupu}
            \label{fig:4_13b}
            \vspace{0pt}
        \end{subfigure}
        \caption{Jednoslojna \acrshort{BRNN} mrezha sa $n=90$ i verovatnoc1om $dropout$ regularizacije $0.1$}
        \label{fig:4_13}
\end{figure}
\newpage
\begin{figure}[!h]
        \centering
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.43]{res/SL_BLSTM_120units_d01_train.png}
            \caption{\acrshort{MSE} na trenirajuc1em skupu}
            \label{fig:4_14a}
            \vspace{0pt}
        \end{subfigure}%
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.43]{res/SL_BLSTM_120units_d01_validation.png}
            \caption{\acrshort{MSE} na validacionom skupu}
            \label{fig:4_14b}
            \vspace{0pt}
        \end{subfigure}
        \caption{Jednoslojna \acrshort{BRNN} mrezha sa $n=120$ i verovatnoc1om $dropout$ regularizacije $0.1$}
        \label{fig:4_14}
\end{figure}
\begin{figure}[!h]
        \centering
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.43]{res/SL_BLSTM_150units_d01_train.png}
            \caption{\acrshort{MSE} na trenirajuc1em skupu}
            \label{fig:4_15a}
            \vspace{0pt}
        \end{subfigure}%
        \begin{subfigure}{0.475\textwidth}
            \centering
            \includegraphics[scale=0.43]{res/SL_BLSTM_150units_d01_validation.png}
            \caption{\acrshort{MSE} na validacionom skupu}
            \label{fig:4_15b}
            \vspace{0pt}
        \end{subfigure}
        \caption{Jednoslojna \acrshort{BRNN} mrezha sa $n=150$ i verovatnoc1om $dropout$ regularizacije $0.1$}
        \label{fig:4_15}
\end{figure}

\chapter{Sinteza videa}
U ovom poglavlju c1e biti predstavljen jednostavan nachin na koji se mozhe doc1i do lazhnog videa.\\ 
Poput rada \cite{deepfake2}, ideja je da se iskoristi ciljni (eng. $targert$) video iz koga c1e se uzeti oni frejmovi na kojima oblik usta najvishe odgovara. Kako bi se dobili oblici usta za neki audio snimak, potrebno je propustiti audio snimak kroz odabran model neuralne mrezhe. Za pogodan model uzet je model chiji su grafici obuchavanja prikazani na slici \ref{fig:4_14}. Audio snimak je potrebno prethodno normalizovati uz pomoc1 \cite{FFmpegN}, a zatim i odrediti \acrshort{MFKK}. \acrshort{MFKK} koeficijente je potrebno podeliti na sekvence duzhine 100. Izlaz modela predstavlja 17 koordinata usta, ali je potrebno izvrshiti njihovo risemplovanje na manju frekvenciju odabiranja da bi se dobila frekvencija koja se podudara sa brojem frejmova u sekundi ciljnog videa. Nakon toga se u ciljnom videu trazhe frejmovi chiji $3D$ modeli sadrzhe najpriblizhinije koordinate onima dobijenih kao izlaz modela. Poseban problem predstavlja renderovanje $3D$ modela u $2D$ sliku, buduc1i da $Microsoft$ alati kao shto su $3D$ $Paint$ i $3D$ $Viewer$ ne nude \acrshort{API} funkcionalnosti pomoc1u kojeg bi se lako isprogramiralo postavljanje modela u fronatlnu poziciju da se vidi lice i chuvanje tog prikaza. Za reshavanje tog problema, kao njlakshim i najefikasnijim reshenjem pokazala se $LabVIEW$ biblioteka $Haro3D$ \cite{Haro3D}. Nakon ovog koraka dobija se se sekvenca slika osobe koja pricha, koje je potrebno spojiti u video. To se mozhe lako realizovati uz pomoc $FFmpeg$ alata, uz pomoc1 kog se lako, na tako napravljen video, doda pochetna audio sekvenca.\\
Primerak dobijenog videa mozhe se videti na \cite{yt}. Mana ove metode je shto ostale tachke lica nemaju prirodne promene izmedju frejmova, buduc1i da su modeli naucheni da prepoznaju pridne promene polozhaja usta tokom govora. Takodje se mozhe primetiti da kvalitet jako degradira i mala rezolucija dostupnog \acrshort{SFM} modela, korish\-c1enog pri $3D$ modelovanju.
\chapter{Zakljuchak} 
U ovom radu je uspeshno realizovano obuchavanje modela rekurentnih neuralnih mrezha sa ciljem da se nauchi mapiranje sekvence karakteristichnih parametara govora na sekvence oblika usta. Predstavljen je nachin na koji se mogu dobiti karakteristichna obelezhja audio i video snimaka, kao i pokazano je da se najmanja greshka pri obuchavanju ostvaruje bidirekcionim \acrshort{LSTM} mrezhama. Na kraju je predstavljen jednostavan nachin na koji se mozhe doc1i do videa, koji mozhe predstavljati osnovu za dobijanje uverljivijeg lazhnog videa.\\
Dalje unapredjenje rada bi se zasnivalo na usavrshavanju $3D$ modela lica, korish\-c1enjem modela visoke rezolucije, sa ciljem da se dobiju prezicniji prikazi oblika usta. U te svrhe se mozhe pokushati i sa vec1im brojem $3D$ koordinata, koje ne pripadaju samo usnama nego i ostalim regionima u predelu usta.\\
Pored sve boljih modela veshtachke inteligencije, $deepfake$ algoritimi i dalje se najvishe baziraju na algoritmima obrade slike. Predstavljen nachin za generisanje videa nije dovoljno dobar da stvori realistichnije prelaze izmedju najboljih frejmova ciljnog videa za ostale regione lica. To bi se moglo unaprediti algoritmima kompjuterske vizije. Takodje bi se video mogao unaprediti dodavanjem ostalih vizuelnih elemenata kao shto su pozadina i ostali elementi lica koje $3D$ modeli ne modeluju poput kose i zuba. 


\begin{thebibliography}{99}
\bibitem{OPGpredavanja}
Djurovic1, Zh. Materijali sa predmeta Obrada i prepoznavanje govora
\bibitem{POpredavanja}
Djurovic1, Zh. Materijali sa predmeta Prepoznavanje oblika
\bibitem{MUpredavanja}
Tadic1, P. Materijali sa predmeta Mashinsko uchenje
\bibitem{kepstrum}
Delic1, V. Analiza mel-frekvencijskih kepstralnih koeficijenata kao obelezhja korish\-c1enih pri automat\-skom prepoznavanju govornika
\fontencoding{T1}\selectfont
\bibitem{deepfake1}
Christoph Bregler, Michele Covell, Malcolm Slaney. Video Rewrite: Driving Visual Speech with Audio. Interval Researh Corporation, 1997.
\bibitem{deepfake2}
Supasorn Suwajanakorn, Steven M. Seitz, Ira Kemelmacher-Shlizerman. Synthesizing Obama: Learning Lip Sync from Audio. University of Washington, 2017.
\bibitem{MFKKlink}
\url{http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/}
\bibitem{FFmpeg}
\url{https://ffmpeg.org/}
\bibitem{FFmpegN}
\url{https://github.com/slhck/ffmpeg-normalize}
\bibitem{Backprog}
David E. Rumelhart, Geoffrey E. Hinton, and Ronald J. Williams. Learning
internal representations by error propagation. Technical report, DTIC Document, 1985.
\bibitem{AdaDelta}
Matthew D. Zeiler. Adadelta: an adaptive learning rate method. arXiv preprint arXiv:1212.5701, 2012.
\bibitem{AdaGrad}
John Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for
online learning and stochastic optimization. The Journal of Machine Learning Research, 12:2121–2159, 2011.
\bibitem{RMSprop}
Tijmen Tieleman and Geoffrey E. Hinton. Lecture 6.5- RMSprop: Divide
the gradient by a running average of its recent magnitude, 2012.
\bibitem{Adam}
Diederik P. Kingma, Jimmy Ba, Adam: A Method for Stochastic Optimization, 2014.
\bibitem{Hopfild}
John J. Hopfield. Neural networks and physical systems with emergent collective
computational abilities. Proceedings of the National Academy of Sciences, 79(8):2554–2558, 1982.
\bibitem{jordan}
Michael I. Jordan. Serial order: A parallel distributed processing approach.
Technical Report 8604, Institute for Cognitive Science, University of California, San Diego, 1986.
\bibitem{Sutskever}
Ilya Sutskever, Oriol Vinyals, and Quoc V. Le. Sequence to sequence learning
with neural networks. In Advances in Neural Information Processing Systems,
pages 3104–3112, 2014.
\bibitem{Elman}
Jeffrey L. Elman. Finding structure in time. Cognitive science, 14(2):179–211,1990.
\bibitem{Bengio}
Bengio, Y., Simard, P., and Frasconi, P. (1994). Learning long-term dependencies with gradient descent is
difficult. IEEE Transactions on Neural Networks,5(2), 157–166
\bibitem{BPTT}
Werbos, P. (1990). Backpropagation through time: what it does and how to do it. Proceedings of the
IEEE, 78(10):1550–1560.
\bibitem{TBPTT}
Ronald J. Williams and David Zipser. A learning algorithm for continually running fully recurrent neural networks. Neural Computation, 1(2):270–280,1989.
\bibitem{LSTM}
Sepp Hochreiter and J¨urgen Schmidhuber. Long short-term memory. Neural Computation, 9(8):1735–1780, 1997.
\bibitem{BLSTM}
Mike Schuster and Kuldip K. Paliwal. Bidirectional recurrent neural networks.
Signal Processing, IEEE Transactions on, 45(11):2673–2681, 1997.
\bibitem{forget gate}
Felix A. Gers, J¨urgen Schmidhuber, and Fred Cummins. Learning to forget:
Continual prediction with LSTM. Neural computation, 12(10):2451–2471,
2000.
\bibitem{Opencv}
\url{https://opencv.org/}
\bibitem{Haar}
Paul Viola, Michael Jones. Rapid Object Detection using a Boosted Cascade of Simple Features. Conference on Computer Vision and Pattern Recognition, 2001.
\bibitem{LBF}
Shaoqing Ren, Xudong Cao, Yichen Wei, Jian Sun. Face Alignment at 3000 FPS via Regressing Binary Features, 2014.
\bibitem{3DMM}
Blanz, V. and Vetter, T. (1999). A Morphable Model for the
synthesis of 3D faces. In Proceedings of the 26th Annual Conference on Computer Graphics and Interactive Techniques (SIGGRAPH), pages 187–194. ACM
Press/Addison-Wesley Publishing Co.
\bibitem{AAM}
Cootes, T., Edwards, G., and Taylor, C. (2001). Active appearance models. IEEE Transactions on Pattern Analysis and Machine Intelligence, 23(6):681–685.
\bibitem{SFM}
Patrik Huber, Guosheng Hu, Rafael Tena, Pouria Mortazavian, Willem P. Koppen, William Christmas, Matthias R{\"a}tsch and Josef Kittler. A Multiresolution 3D Morphable Face Model and Fitting Framework. Centre for Vision, Speech \& Signal Processing, University of Surrey. 2016
\bibitem{eos}
\url{https://github.com/patrikhuber/eos}
\bibitem{obj}
\url{https://en.wikipedia.org/wiki/Wavefront_.obj_file}
\bibitem{TF}
\url{https://www.tensorflow.org/}
\bibitem{gh1}
\url{https://github.com/vseselj/3DMorphableFace}
\bibitem{Haro3D}
\url{http://sine.ni.com/nips/cds/view/p/lang/en/nid/213510}
\bibitem{yt}
\url{https://youtu.be/x0foFozDmDQ}
\bibitem{dropout}
\url{https://machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/}
\end{thebibliography}

\newpage
\listoffigures
\listoftables

\newpage
\addcontentsline{toc}{chapter}{Spisak skrac1enica}
\printglossary[title=Spisak skrac1enica, type=\acronymtype]
\end{document}
